
var documents = [{
    "id": 0,
    "url": "https://uwesterr.github.io/404.html",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "https://uwesterr.github.io/about/",
    "title": "About Me",
    "body": "Interested in machine learning since 2014, using it to improve laser communication in space and spreading the idea by teaching at:  University of applied science Esslingen VHS Esslingen"
    }, {
    "id": 2,
    "url": "https://uwesterr.github.io/categories/",
    "title": "Tags",
    "body": "Contents: {% if site. categories. size &gt; 0 %} {% for category in site. categories %} {% capture category_name %}{{ category | first }}{% endcapture %} {{ category_name }}{% endfor %}{% endif %} {% for category in site. categories %}  {% capture category_name %}{{ category | first }}{% endcapture %} &lt;h3 id = {{ category_name }} &gt;&lt;i class= fas fa-tags category-tags-icon &gt;&lt;/i&gt;&lt;/i&gt; {{ category_name }}&lt;/h3&gt;&lt;a name= {{ category_name | slugize }} &gt;&lt;/a&gt;{% for post in site. categories[category_name] %}{%- assign date_format = site. minima. date_format | default:  %b %-d, %Y  -%}&lt;article class= archive-item &gt; &lt;p class= post-meta post-meta-title &gt;&lt;a class= page-meta  href= {{ site. baseurl }}{{ post. url }} &gt;{{post. title}}&lt;/a&gt; • {{ post. date | date: date_format }}&lt;/p&gt;&lt;/article&gt;{% endfor %} {% endfor %}"
    }, {
    "id": 3,
    "url": "https://uwesterr.github.io/images/copied_from_nb/",
    "title": "",
    "body": "WarningDo not manually save images into this folder. This is used by GitHub Actions to automatically copy images.  Any images you save into this folder could be deleted at build time. "
    }, {
    "id": 4,
    "url": "https://uwesterr.github.io/donkeycar/colab/2020/03/01/TrainDonkeyCar.html",
    "title": "Train donkeycar with GPU support in Colab",
    "body": "2020/03/01 -           Credit&#182;    Note: This notebook is based on https://colab. research. google. com/github/robocarstore/donkey-car-training-on-google-colab/blob/master/Donkey_Car_Training_using_Google_Colab. ipynb Check GPU allocation&#182;: If  Found GPU at: / device: GPU: 0  is displayed, the GPU is ready to use.     Note: Donkeycar at the time of writing in March 2020 uses Tensorflow 1. 13, therefore version 1. xx is installed              #collapse-show %tensorflow_version 1. 13. 1import tensorflowprint(tensorflow. __version__)     `%tensorflow_version` only switches the major version: `1. x` or `2. x`. You set: `1. 13. 1`. This will be interpreted as: `1. x`. TensorFlow 1. x selected. 1. 15. 0  Git Clone the donkeycar repository&#182;: Get the latest donkeycar from GitHub     Note: The default branch is  dev , however, the documentation is for the master branch.       !git clone https://github. com/autorope/donkeycar. git %cd /content/donkeycar!git checkout master  Cloning into &#39;donkeycar&#39;. . . remote: Enumerating objects: 146, done. remote: Counting objects: 100% (146/146), done. remote: Compressing objects: 100% (68/68), done. remote: Total 12082 (delta 57), reused 130 (delta 47), pack-reused 11936Receiving objects: 100% (12082/12082), 65. 18 MiB | 29. 06 MiB/s, done. Resolving deltas: 100% (7548/7548), done. /content/donkeycarBranch &#39;master&#39; set up to track remote branch &#39;master&#39; from &#39;origin&#39;. Switched to a new branch &#39;master&#39;  Install donkey car&#182;: Different to the description at http://docs. donkeycar. com/guide/host_pc/setup_ubuntu/ we create no anaconda environment since the script is supposed to run on Colab which will delete the instance anyway       !pip3 install -e . [pc]  Obtaining file:///content/donkeycarRequirement already satisfied: numpy in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (1. 17. 5)Requirement already satisfied: pillow in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (6. 2. 2)Requirement already satisfied: docopt in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (0. 6. 2)Requirement already satisfied: tornado in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (4. 5. 3)Requirement already satisfied: requests in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (2. 21. 0)Requirement already satisfied: h5py in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (2. 8. 0)Requirement already satisfied: moviepy in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (0. 2. 3. 5)Requirement already satisfied: pandas in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (0. 25. 3)Requirement already satisfied: PrettyTable in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (0. 7. 2)Collecting paho-mqtt Downloading https://files. pythonhosted. org/packages/59/11/1dd5c70f0f27a88a3a05772cd95f6087ac479fac66d9c7752ee5e16ddbbc/paho-mqtt-1. 5. 0. tar. gz (99kB)   |████████████████████████████████| 102kB 8. 4MB/s Requirement already satisfied: matplotlib in /usr/local/lib/python3. 6/dist-packages (from donkeycar==3. 1. 1) (3. 1. 3)Requirement already satisfied: chardet&lt;3. 1. 0,&gt;=3. 0. 2 in /usr/local/lib/python3. 6/dist-packages (from requests-&gt;donkeycar==3. 1. 1) (3. 0. 4)Requirement already satisfied: idna&lt;2. 9,&gt;=2. 5 in /usr/local/lib/python3. 6/dist-packages (from requests-&gt;donkeycar==3. 1. 1) (2. 8)Requirement already satisfied: urllib3&lt;1. 25,&gt;=1. 21. 1 in /usr/local/lib/python3. 6/dist-packages (from requests-&gt;donkeycar==3. 1. 1) (1. 24. 3)Requirement already satisfied: certifi&gt;=2017. 4. 17 in /usr/local/lib/python3. 6/dist-packages (from requests-&gt;donkeycar==3. 1. 1) (2019. 11. 28)Requirement already satisfied: six in /usr/local/lib/python3. 6/dist-packages (from h5py-&gt;donkeycar==3. 1. 1) (1. 12. 0)Requirement already satisfied: imageio&lt;3. 0,&gt;=2. 1. 2 in /usr/local/lib/python3. 6/dist-packages (from moviepy-&gt;donkeycar==3. 1. 1) (2. 4. 1)Requirement already satisfied: decorator&lt;5. 0,&gt;=4. 0. 2 in /usr/local/lib/python3. 6/dist-packages (from moviepy-&gt;donkeycar==3. 1. 1) (4. 4. 1)Requirement already satisfied: tqdm&lt;5. 0,&gt;=4. 11. 2 in /usr/local/lib/python3. 6/dist-packages (from moviepy-&gt;donkeycar==3. 1. 1) (4. 28. 1)Requirement already satisfied: pytz&gt;=2017. 2 in /usr/local/lib/python3. 6/dist-packages (from pandas-&gt;donkeycar==3. 1. 1) (2018. 9)Requirement already satisfied: python-dateutil&gt;=2. 6. 1 in /usr/local/lib/python3. 6/dist-packages (from pandas-&gt;donkeycar==3. 1. 1) (2. 6. 1)Requirement already satisfied: kiwisolver&gt;=1. 0. 1 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;donkeycar==3. 1. 1) (1. 1. 0)Requirement already satisfied: cycler&gt;=0. 10 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;donkeycar==3. 1. 1) (0. 10. 0)Requirement already satisfied: pyparsing!=2. 0. 4,!=2. 1. 2,!=2. 1. 6,&gt;=2. 0. 1 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;donkeycar==3. 1. 1) (2. 4. 6)Requirement already satisfied: setuptools in /usr/local/lib/python3. 6/dist-packages (from kiwisolver&gt;=1. 0. 1-&gt;matplotlib-&gt;donkeycar==3. 1. 1) (45. 1. 0)Building wheels for collected packages: paho-mqtt Building wheel for paho-mqtt (setup. py) . . . done Created wheel for paho-mqtt: filename=paho_mqtt-1. 5. 0-cp36-none-any. whl size=61416 sha256=47fecced95422f3f8c63e74f832a05698c847da857f7ea0d9edc18cba1d7875f Stored in directory: /root/. cache/pip/wheels/02/94/6c/8474137cb7a5a3e001d70a22c8ff919caee69435376bccce79Successfully built paho-mqttInstalling collected packages: paho-mqtt, donkeycar Running setup. py develop for donkeycarSuccessfully installed donkeycar paho-mqtt-1. 5. 0  Create Project&#182;: In this step the follwoing actions take place create necessary folders (models, data, logs)copying necessary files into folders (manage. py, myconfig. py etc. )      !donkey createcar --path /content/mycar  using donkey v3. 1. 1 . . . Creating car folder: /content/mycarmaking dir /content/mycarCreating data &amp; model folders. making dir /content/mycar/modelsmaking dir /content/mycar/datamaking dir /content/mycar/logsCopying car application template: completeCopying car config defaults. Adjust these before starting your car. Copying train script. Adjust these before starting your car. Copying my car config overridesDonkey setup complete.   Prepare Data&#182;: In order to train the neural network we need to supply trainings data which are recorded on the pi during driving the donkeycar on the track Copy the following code and run on pi&#182;:     Note: Copying of the data is much faster if the data is zipped to one file. cd ~/mycar/data# either compress just one foldertar -czf tub_xx_yyyy_mm_dd. tar. gz tub_xx_yyyy_mm_dd# or all folders starting with &quot;tub&quot;tar -czf trainingsData2020_03-01. tar. gz tub*This will create a tub_xx_yyyy_mm_dd. tar. gz file under ~/mycar/data Upload Data&#182;: Copy the tub to your local pc&#182;: Run this on your local pc if you are using linux/mac sftp pi@raspberry. localcd ~/mycar/dataget tub_xx_yyyy_mm_dd. tar. gzIf you are on a windows, download sftp utility like filezilla or putty Define your tub name here&#182;:       tub_name=&quot;tubVaihingenIIICleaned200126&quot;    Upload the tub to Google Drive&#182;: First upload the tub_x_yyyy_mm_dd. tar. gz to Google Drive. We will then mount Google Drive from colab and copy the data from Drive directly.     Note: To copy data from Google Drive to Colab is faster than uplaoding it from local machine.  When you run the cell below, you will need to click the link and generate an authorization code to for colab to access your drive.       from google. colab import drivedrive. mount(&#39;/content/drive&#39;)    Suppose you upload the tub_xx_yyyy_mm_dd. tar. gz to Google Drive/mycar/tub_xx_yyyy_mm_dd. tar. gz, this is how you copy it from Google Drive to colab       %cd /content/mycar!rm -rf data!mkdir data%cd /content/mycar/data!cp /content/drive/My\ Drive/myCar/{tub_name}. tar. gz .   /content/mycar/content/mycar/data  Upload local files&#182;: You can upload files from local machine as well, but probably is slower than above approach downloading files from Google Drive       from google. colab import files# uploaded = files. upload()    Get myconfig. py&#182;:     Note: In myconfig. py therer are parameters which control the training such as:  line parameter --type to the python manage. py train and drive commands. DEFAULT_MODEL_TYPE = 'linear'  (linear|categorical|rnn|imu|behavior|3d|localizer|latent) BATCH_SIZE = 128        how many records to use when doing one pass of gradient decent. Use a smaller number if your gpu is running out of memory. TRAIN_TEST_SPLIT = 0. 8     what percent of records to use for training. the remaining used for validation. MAX_EPOCHS = 100        how many times to visit all records of your data SHOW_PLOT = True        would you like to see a pop up display of final loss? VEBOSE_TRAIN = True       would you like to see a progress bar with text during training? USE_EARLY_STOP = True      would you like to stop the training if we see it's not improving fit? EARLY_STOP_PATIENCE = 5     how many epochs to wait before no improvement MIN_DELTA = . 0005        early stop will want this much loss change before calling it improved. PRINT_MODEL_SUMMARY = True   print layers and weights to stdout OPTIMIZER = None        adam, sgd, rmsprop, etc. . None accepts default LEARNING_RATE = 0. 001      only used when OPTIMIZER specified LEARNING_RATE_DECAY = 0. 0    only used when OPTIMIZER specified SEND_BEST_MODEL_TO_PI = False  change to true to automatically send best model during training CACHE_IMAGES = True       keep images in memory. will speed succesive epochs, but crater if not enough mem. PRUNE_CNN = False        This will remove weights from your model. The primary goal is to increase performance. PRUNE_PERCENT_TARGET = 75    The desired percentage of pruning. PRUNE_PERCENT_PER_ITERATION = 20 Percenge of pruning that is perform per iteration. PRUNE_VAL_LOSS_DEGRADATION_LIMIT = 0. 2 The max amout of validation loss that is permitted during pruning. PRUNE_EVAL_PERCENT_OF_DATASET = . 05  percent of dataset used to perform evaluation of model. RNN or 3D SEQUENCE_LENGTH = 3       #some models use a number of images over time. This controls how many.  # # Region of interst cropping# # only supported in Categorical and Linear models. ROI_CROP_TOP = 0          #the number of rows of pixels to ignore on the top of the image  ROI_CROP_BOTTOM = 0      #the number of rows of pixels to ignore on the bottom of the image      %cd /content/mycar!cp /content/drive/My\ Drive/myCar/myconfig. py .   /content/mycar  Upload pre-trained model&#182;: Upload model in case you want to use a pre-trained model for transfer learning. To define which layers shall be trained and which shall be frozen set the parameters in `myconfig. py`` Model transfer options When copying weights during a model transfer operation, should we freeze a certain number of layers to the incoming weights and not allow them to change during training? FREEZE_LAYERS = False        #default False will allow all layers to be modified by trainingNUM_LAST_LAYERS_TO_TRAIN = 7    #when freezing layers, how many layers from the last should be allowed to train?      %cd /content/mycar/models!cp /content/drive/My\ Drive/myCar/base_linear. h5 .   /content/mycar/models  And untar it to the right place       %cd /content/mycar/data!tar -xzf {tub_name}. tar. gz  /content/mycar/data  To check whether data are available lets look at an image       from google. colab import filesfrom IPython. display import Imageimport glob%cd /content/mycar/data/tubVaihingenIIICleaned200126/file = glob. glob(&quot;*. jpg&quot;)Image(file[100])  /content/mycar/data/tubVaihingenIIICleaned200126  Transfer training of model&#182;: Dont forget to set the variables in config. py FREEZE_LAYERS = True `#default False will allow all layers to be modified by trainingNUM_LAST_LAYERS_TO_TRAIN = 7 `#when freezing layers, how many layers from the last should be allowed to train?      !python /content/mycar/manage. py train --type=linear --transfer=/content/mycar/models/base_linear. h5 --model=/content/mycar/models/mypilot. h5  using donkey v3. 1. 1 . . . loading config file: /content/mycar/config. pyloading personal config over-ridesconfig loaded&#34;get_model_by_type&#34; model Type is: linearWARNING:tensorflow:From /usr/local/lib/python3. 6/dist-packages/tensorflow_core/python/ops/resource_variable_ops. py:1630: calling BaseResourceVariable. __init__ (from tensorflow. python. ops. resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:If using Keras pass *_constraint arguments to layers. training with model type &lt;class &#39;donkeycar. parts. keras. KerasLinear&#39;&gt;loading weights from model /content/mycar/models/base_linear. h5WARNING:tensorflow:From /usr/local/lib/python3. 6/dist-packages/tensorflow_core/python/ops/init_ops. py:97: calling Zeros. __init__ (from tensorflow. python. ops. init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating:Call initializer instance with the dtype argument instead of passing it to the constructorWARNING:tensorflow:From /usr/local/lib/python3. 6/dist-packages/tensorflow_core/python/ops/init_ops. py:97: calling Ones. __init__ (from tensorflow. python. ops. init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating:Call initializer instance with the dtype argument instead of passing it to the constructorWARNING:tensorflow:From /usr/local/lib/python3. 6/dist-packages/tensorflow_core/python/ops/init_ops. py:97: calling GlorotUniform. __init__ (from tensorflow. python. ops. init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating:Call initializer instance with the dtype argument instead of passing it to the constructor2020-03-01 20:15:10. 883730: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcuda. so. 12020-03-01 20:15:10. 947706: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:10. 948244: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1618] Found device 0 with properties: name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1. 1135pciBusID: 0000:00:04. 02020-03-01 20:15:10. 959625: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudart. so. 10. 12020-03-01 20:15:11. 211248: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcublas. so. 102020-03-01 20:15:11. 355358: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcufft. so. 102020-03-01 20:15:11. 375728: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcurand. so. 102020-03-01 20:15:11. 655257: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusolver. so. 102020-03-01 20:15:11. 674134: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusparse. so. 102020-03-01 20:15:12. 199157: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudnn. so. 72020-03-01 20:15:12. 199319: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 200012: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 200537: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1746] Adding visible gpu devices: 02020-03-01 20:15:12. 201047: I tensorflow/core/platform/cpu_feature_guard. cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F2020-03-01 20:15:12. 252078: I tensorflow/core/platform/profile_utils/cpu_utils. cc:94] CPU Frequency: 2000170000 Hz2020-03-01 20:15:12. 253836: I tensorflow/compiler/xla/service/service. cc:168] XLA service 0x6466fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:2020-03-01 20:15:12. 253872: I tensorflow/compiler/xla/service/service. cc:176]  StreamExecutor device (0): Host, Default Version2020-03-01 20:15:12. 376300: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 376808: I tensorflow/compiler/xla/service/service. cc:168] XLA service 0x6467180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:2020-03-01 20:15:12. 376842: I tensorflow/compiler/xla/service/service. cc:176]  StreamExecutor device (0): Tesla P4, Compute Capability 6. 12020-03-01 20:15:12. 378134: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 378502: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1618] Found device 0 with properties: name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1. 1135pciBusID: 0000:00:04. 02020-03-01 20:15:12. 378563: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudart. so. 10. 12020-03-01 20:15:12. 378589: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcublas. so. 102020-03-01 20:15:12. 378614: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcufft. so. 102020-03-01 20:15:12. 378637: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcurand. so. 102020-03-01 20:15:12. 378659: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusolver. so. 102020-03-01 20:15:12. 378681: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusparse. so. 102020-03-01 20:15:12. 378704: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudnn. so. 72020-03-01 20:15:12. 378771: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 379204: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 379549: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1746] Adding visible gpu devices: 02020-03-01 20:15:12. 384332: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudart. so. 10. 12020-03-01 20:15:12. 385363: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:2020-03-01 20:15:12. 385397: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1165]   0 2020-03-01 20:15:12. 385410: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1178] 0:  N 2020-03-01 20:15:12. 386633: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 387098: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-01 20:15:12. 387514: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator. cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0. 2020-03-01 20:15:12. 387563: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -&gt; physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04. 0, compute capability: 6. 1)Model: &#34;model&#34;__________________________________________________________________________________________________Layer (type)          Output Shape     Param #   Connected to           ==================================================================================================img_in (InputLayer)       [(None, 120, 160, 3) 0                      __________________________________________________________________________________________________cropping2d (Cropping2D)     (None, 120, 160, 3) 0      img_in[0][0]           __________________________________________________________________________________________________batch_normalization_v1 (BatchNo (None, 120, 160, 3) 12     cropping2d[0][0]         __________________________________________________________________________________________________conv2d_1 (Conv2D)        (None, 58, 78, 24)  1824    batch_normalization_v1[0][0]   __________________________________________________________________________________________________dropout (Dropout)        (None, 58, 78, 24)  0      conv2d_1[0][0]          __________________________________________________________________________________________________conv2d_2 (Conv2D)        (None, 27, 37, 32)  19232    dropout[0][0]          __________________________________________________________________________________________________dropout_1 (Dropout)       (None, 27, 37, 32)  0      conv2d_2[0][0]          __________________________________________________________________________________________________conv2d_3 (Conv2D)        (None, 12, 17, 64)  51264    dropout_1[0][0]         __________________________________________________________________________________________________dropout_2 (Dropout)       (None, 12, 17, 64)  0      conv2d_3[0][0]          __________________________________________________________________________________________________conv2d_4 (Conv2D)        (None, 10, 15, 64)  36928    dropout_2[0][0]         __________________________________________________________________________________________________dropout_3 (Dropout)       (None, 10, 15, 64)  0      conv2d_4[0][0]          __________________________________________________________________________________________________conv2d_5 (Conv2D)        (None, 8, 13, 64)  36928    dropout_3[0][0]         __________________________________________________________________________________________________dropout_4 (Dropout)       (None, 8, 13, 64)  0      conv2d_5[0][0]          __________________________________________________________________________________________________flattened (Flatten)       (None, 6656)     0      dropout_4[0][0]         __________________________________________________________________________________________________dense (Dense)          (None, 100)     665700   flattened[0][0]         __________________________________________________________________________________________________dropout_5 (Dropout)       (None, 100)     0      dense[0][0]           __________________________________________________________________________________________________dense_1 (Dense)         (None, 50)      5050    dropout_5[0][0]         __________________________________________________________________________________________________dropout_6 (Dropout)       (None, 50)      0      dense_1[0][0]          __________________________________________________________________________________________________n_outputs0 (Dense)       (None, 1)      51     dropout_6[0][0]         __________________________________________________________________________________________________n_outputs1 (Dense)       (None, 1)      51     dropout_6[0][0]         ==================================================================================================Total params: 817,040Trainable params: 817,034Non-trainable params: 6__________________________________________________________________________________________________Nonefound 0 pickles writing json records and images in tub /content/mycar/data/tubVaihingenIIICleaned200126/content/mycar/data/tubVaihingenIIICleaned200126collating 14234 records . . . train: 11387, val: 2847total records: 14234steps_per_epoch 177Epoch 1/1002020-03-01 20:15:22. 207108: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcublas. so. 102020-03-01 20:15:23. 704226: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudnn. so. 7176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 3655 - n_outputs0_loss: 0. 2319 - n_outputs1_loss: 0. 1336Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 6s - loss: 0. 6712 - n_outputs0_loss: 0. 6156 - n_outputs1_loss: 0. 0556Epoch 00001: val_loss improved from inf to 0. 67117, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 20s 110ms/step - loss: 0. 3644 - n_outputs0_loss: 0. 2315 - n_outputs1_loss: 0. 1329 - val_loss: 0. 6712 - val_n_outputs0_loss: 0. 6156 - val_n_outputs1_loss: 0. 0556Epoch 2/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1945 - n_outputs0_loss: 0. 1760 - n_outputs1_loss: 0. 0186Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 6794 - n_outputs0_loss: 0. 6145 - n_outputs1_loss: 0. 0649Epoch 00002: val_loss did not improve from 0. 67117177/177 [==============================] - 7s 40ms/step - loss: 0. 1942 - n_outputs0_loss: 0. 1755 - n_outputs1_loss: 0. 0187 - val_loss: 0. 6821 - val_n_outputs0_loss: 0. 6175 - val_n_outputs1_loss: 0. 0646Epoch 3/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1753 - n_outputs0_loss: 0. 1604 - n_outputs1_loss: 0. 0149Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 6618 - n_outputs0_loss: 0. 6397 - n_outputs1_loss: 0. 0221Epoch 00003: val_loss improved from 0. 67117 to 0. 65910, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 41ms/step - loss: 0. 1754 - n_outputs0_loss: 0. 1603 - n_outputs1_loss: 0. 0151 - val_loss: 0. 6591 - val_n_outputs0_loss: 0. 6367 - val_n_outputs1_loss: 0. 0224Epoch 4/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1680 - n_outputs0_loss: 0. 1541 - n_outputs1_loss: 0. 0140Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 6526 - n_outputs0_loss: 0. 6090 - n_outputs1_loss: 0. 0437Epoch 00004: val_loss improved from 0. 65910 to 0. 65629, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 41ms/step - loss: 0. 1682 - n_outputs0_loss: 0. 1543 - n_outputs1_loss: 0. 0139 - val_loss: 0. 6563 - val_n_outputs0_loss: 0. 6137 - val_n_outputs1_loss: 0. 0426Epoch 5/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1555 - n_outputs0_loss: 0. 1425 - n_outputs1_loss: 0. 0131Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 3074 - n_outputs0_loss: 0. 2934 - n_outputs1_loss: 0. 0140Epoch 00005: val_loss improved from 0. 65629 to 0. 30737, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 42ms/step - loss: 0. 1554 - n_outputs0_loss: 0. 1424 - n_outputs1_loss: 0. 0130 - val_loss: 0. 3074 - val_n_outputs0_loss: 0. 2934 - val_n_outputs1_loss: 0. 0140Epoch 6/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1444 - n_outputs0_loss: 0. 1319 - n_outputs1_loss: 0. 0125Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1706 - n_outputs0_loss: 0. 1567 - n_outputs1_loss: 0. 0139Epoch 00006: val_loss improved from 0. 30737 to 0. 16886, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 42ms/step - loss: 0. 1445 - n_outputs0_loss: 0. 1320 - n_outputs1_loss: 0. 0124 - val_loss: 0. 1689 - val_n_outputs0_loss: 0. 1557 - val_n_outputs1_loss: 0. 0132Epoch 7/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1409 - n_outputs0_loss: 0. 1288 - n_outputs1_loss: 0. 0121Epoch 1/100 43/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1527 - n_outputs0_loss: 0. 1426 - n_outputs1_loss: 0. 0101Epoch 00007: val_loss improved from 0. 16886 to 0. 15216, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 42ms/step - loss: 0. 1404 - n_outputs0_loss: 0. 1283 - n_outputs1_loss: 0. 0120 - val_loss: 0. 1522 - val_n_outputs0_loss: 0. 1422 - val_n_outputs1_loss: 0. 0099Epoch 8/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1314 - n_outputs0_loss: 0. 1197 - n_outputs1_loss: 0. 0117Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1412 - n_outputs0_loss: 0. 1300 - n_outputs1_loss: 0. 0111Epoch 00008: val_loss improved from 0. 15216 to 0. 14233, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 41ms/step - loss: 0. 1318 - n_outputs0_loss: 0. 1202 - n_outputs1_loss: 0. 0117 - val_loss: 0. 1423 - val_n_outputs0_loss: 0. 1312 - val_n_outputs1_loss: 0. 0112Epoch 9/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1284 - n_outputs0_loss: 0. 1176 - n_outputs1_loss: 0. 0108Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1540 - n_outputs0_loss: 0. 1463 - n_outputs1_loss: 0. 0077Epoch 00009: val_loss did not improve from 0. 14233177/177 [==============================] - 7s 40ms/step - loss: 0. 1285 - n_outputs0_loss: 0. 1177 - n_outputs1_loss: 0. 0108 - val_loss: 0. 1513 - val_n_outputs0_loss: 0. 1438 - val_n_outputs1_loss: 0. 0076Epoch 10/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1196 - n_outputs0_loss: 0. 1093 - n_outputs1_loss: 0. 0103Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1441 - n_outputs0_loss: 0. 1379 - n_outputs1_loss: 0. 0062Epoch 00010: val_loss did not improve from 0. 14233177/177 [==============================] - 7s 40ms/step - loss: 0. 1195 - n_outputs0_loss: 0. 1092 - n_outputs1_loss: 0. 0103 - val_loss: 0. 1441 - val_n_outputs0_loss: 0. 1379 - val_n_outputs1_loss: 0. 0062Epoch 11/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1143 - n_outputs0_loss: 0. 1052 - n_outputs1_loss: 0. 0091Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1321 - n_outputs0_loss: 0. 1267 - n_outputs1_loss: 0. 0054Epoch 00011: val_loss improved from 0. 14233 to 0. 13208, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 41ms/step - loss: 0. 1149 - n_outputs0_loss: 0. 1057 - n_outputs1_loss: 0. 0092 - val_loss: 0. 1321 - val_n_outputs0_loss: 0. 1267 - val_n_outputs1_loss: 0. 0054Epoch 12/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1106 - n_outputs0_loss: 0. 1008 - n_outputs1_loss: 0. 0098Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1284 - n_outputs0_loss: 0. 1249 - n_outputs1_loss: 0. 0035Epoch 00012: val_loss improved from 0. 13208 to 0. 12771, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 42ms/step - loss: 0. 1104 - n_outputs0_loss: 0. 1006 - n_outputs1_loss: 0. 0098 - val_loss: 0. 1277 - val_n_outputs0_loss: 0. 1243 - val_n_outputs1_loss: 0. 0034Epoch 13/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1059 - n_outputs0_loss: 0. 0968 - n_outputs1_loss: 0. 0091Epoch 1/100 43/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1298 - n_outputs0_loss: 0. 1235 - n_outputs1_loss: 0. 0063Epoch 00013: val_loss did not improve from 0. 12771177/177 [==============================] - 7s 40ms/step - loss: 0. 1058 - n_outputs0_loss: 0. 0968 - n_outputs1_loss: 0. 0091 - val_loss: 0. 1299 - val_n_outputs0_loss: 0. 1237 - val_n_outputs1_loss: 0. 0062Epoch 14/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1016 - n_outputs0_loss: 0. 0927 - n_outputs1_loss: 0. 0089Epoch 1/100 43/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1320 - n_outputs0_loss: 0. 1264 - n_outputs1_loss: 0. 0056Epoch 00014: val_loss did not improve from 0. 12771177/177 [==============================] - 7s 40ms/step - loss: 0. 1016 - n_outputs0_loss: 0. 0928 - n_outputs1_loss: 0. 0088 - val_loss: 0. 1333 - val_n_outputs0_loss: 0. 1278 - val_n_outputs1_loss: 0. 0055Epoch 15/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0953 - n_outputs0_loss: 0. 0867 - n_outputs1_loss: 0. 0086Epoch 1/100 43/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1327 - n_outputs0_loss: 0. 1282 - n_outputs1_loss: 0. 0045Epoch 00015: val_loss did not improve from 0. 12771177/177 [==============================] - 7s 40ms/step - loss: 0. 0952 - n_outputs0_loss: 0. 0867 - n_outputs1_loss: 0. 0086 - val_loss: 0. 1324 - val_n_outputs0_loss: 0. 1280 - val_n_outputs1_loss: 0. 0045Epoch 16/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0932 - n_outputs0_loss: 0. 0850 - n_outputs1_loss: 0. 0082Epoch 1/100 43/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1232 - n_outputs0_loss: 0. 1163 - n_outputs1_loss: 0. 0068Epoch 00016: val_loss improved from 0. 12771 to 0. 12196, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 42ms/step - loss: 0. 0933 - n_outputs0_loss: 0. 0851 - n_outputs1_loss: 0. 0082 - val_loss: 0. 1220 - val_n_outputs0_loss: 0. 1152 - val_n_outputs1_loss: 0. 0068Epoch 17/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0903 - n_outputs0_loss: 0. 0825 - n_outputs1_loss: 0. 0078Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1336 - n_outputs0_loss: 0. 1273 - n_outputs1_loss: 0. 0063Epoch 00017: val_loss did not improve from 0. 12196177/177 [==============================] - 7s 40ms/step - loss: 0. 0904 - n_outputs0_loss: 0. 0826 - n_outputs1_loss: 0. 0078 - val_loss: 0. 1336 - val_n_outputs0_loss: 0. 1273 - val_n_outputs1_loss: 0. 0063Epoch 18/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0875 - n_outputs0_loss: 0. 0799 - n_outputs1_loss: 0. 0076Epoch 1/100 43/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1270 - n_outputs0_loss: 0. 1214 - n_outputs1_loss: 0. 0056Epoch 00018: val_loss did not improve from 0. 12196177/177 [==============================] - 7s 40ms/step - loss: 0. 0877 - n_outputs0_loss: 0. 0801 - n_outputs1_loss: 0. 0075 - val_loss: 0. 1264 - val_n_outputs0_loss: 0. 1209 - val_n_outputs1_loss: 0. 0055Epoch 19/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0853 - n_outputs0_loss: 0. 0777 - n_outputs1_loss: 0. 0076Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1246 - n_outputs0_loss: 0. 1173 - n_outputs1_loss: 0. 0073Epoch 00019: val_loss did not improve from 0. 12196177/177 [==============================] - 7s 40ms/step - loss: 0. 0852 - n_outputs0_loss: 0. 0777 - n_outputs1_loss: 0. 0075 - val_loss: 0. 1235 - val_n_outputs0_loss: 0. 1157 - val_n_outputs1_loss: 0. 0078Epoch 20/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0833 - n_outputs0_loss: 0. 0759 - n_outputs1_loss: 0. 0074Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1280 - n_outputs0_loss: 0. 1212 - n_outputs1_loss: 0. 0068Epoch 00020: val_loss did not improve from 0. 12196177/177 [==============================] - 7s 40ms/step - loss: 0. 0831 - n_outputs0_loss: 0. 0757 - n_outputs1_loss: 0. 0074 - val_loss: 0. 1280 - val_n_outputs0_loss: 0. 1212 - val_n_outputs1_loss: 0. 0068Epoch 21/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0799 - n_outputs0_loss: 0. 0728 - n_outputs1_loss: 0. 0072Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1210 - n_outputs0_loss: 0. 1159 - n_outputs1_loss: 0. 0051Epoch 00021: val_loss improved from 0. 12196 to 0. 12104, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 41ms/step - loss: 0. 0800 - n_outputs0_loss: 0. 0728 - n_outputs1_loss: 0. 0071 - val_loss: 0. 1210 - val_n_outputs0_loss: 0. 1159 - val_n_outputs1_loss: 0. 0051Epoch 22/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0781 - n_outputs0_loss: 0. 0712 - n_outputs1_loss: 0. 0069Epoch 1/100 42/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1234 - n_outputs0_loss: 0. 1171 - n_outputs1_loss: 0. 0062Epoch 00022: val_loss did not improve from 0. 12104177/177 [==============================] - 7s 40ms/step - loss: 0. 0784 - n_outputs0_loss: 0. 0716 - n_outputs1_loss: 0. 0069 - val_loss: 0. 1247 - val_n_outputs0_loss: 0. 1187 - val_n_outputs1_loss: 0. 0060Epoch 23/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0753 - n_outputs0_loss: 0. 0683 - n_outputs1_loss: 0. 0070Epoch 1/100 40/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1234 - n_outputs0_loss: 0. 1173 - n_outputs1_loss: 0. 0062Epoch 00023: val_loss did not improve from 0. 12104177/177 [==============================] - 7s 40ms/step - loss: 0. 0755 - n_outputs0_loss: 0. 0686 - n_outputs1_loss: 0. 0069 - val_loss: 0. 1263 - val_n_outputs0_loss: 0. 1206 - val_n_outputs1_loss: 0. 0057Epoch 24/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0745 - n_outputs0_loss: 0. 0680 - n_outputs1_loss: 0. 0065Epoch 1/100 43/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1170 - n_outputs0_loss: 0. 1110 - n_outputs1_loss: 0. 0060Epoch 00024: val_loss improved from 0. 12104 to 0. 11585, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 7s 42ms/step - loss: 0. 0746 - n_outputs0_loss: 0. 0680 - n_outputs1_loss: 0. 0065 - val_loss: 0. 1159 - val_n_outputs0_loss: 0. 1100 - val_n_outputs1_loss: 0. 0059Epoch 25/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0713 - n_outputs0_loss: 0. 0647 - n_outputs1_loss: 0. 0066Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1176 - n_outputs0_loss: 0. 1096 - n_outputs1_loss: 0. 0080Epoch 00025: val_loss did not improve from 0. 11585177/177 [==============================] - 7s 41ms/step - loss: 0. 0714 - n_outputs0_loss: 0. 0649 - n_outputs1_loss: 0. 0066 - val_loss: 0. 1177 - val_n_outputs0_loss: 0. 1100 - val_n_outputs1_loss: 0. 0078Epoch 26/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0685 - n_outputs0_loss: 0. 0624 - n_outputs1_loss: 0. 0061Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1245 - n_outputs0_loss: 0. 1176 - n_outputs1_loss: 0. 0069Epoch 00026: val_loss did not improve from 0. 11585177/177 [==============================] - 7s 40ms/step - loss: 0. 0683 - n_outputs0_loss: 0. 0622 - n_outputs1_loss: 0. 0062 - val_loss: 0. 1233 - val_n_outputs0_loss: 0. 1159 - val_n_outputs1_loss: 0. 0074Epoch 27/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0681 - n_outputs0_loss: 0. 0619 - n_outputs1_loss: 0. 0062Epoch 1/100 42/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1254 - n_outputs0_loss: 0. 1200 - n_outputs1_loss: 0. 0054Epoch 00027: val_loss did not improve from 0. 11585177/177 [==============================] - 7s 40ms/step - loss: 0. 0680 - n_outputs0_loss: 0. 0618 - n_outputs1_loss: 0. 0062 - val_loss: 0. 1232 - val_n_outputs0_loss: 0. 1178 - val_n_outputs1_loss: 0. 0054Epoch 28/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0651 - n_outputs0_loss: 0. 0592 - n_outputs1_loss: 0. 0059Epoch 1/100 41/177 [=====&gt;. . . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1195 - n_outputs0_loss: 0. 1108 - n_outputs1_loss: 0. 0087Epoch 00028: val_loss did not improve from 0. 11585177/177 [==============================] - 7s 40ms/step - loss: 0. 0651 - n_outputs0_loss: 0. 0592 - n_outputs1_loss: 0. 0059 - val_loss: 0. 1193 - val_n_outputs0_loss: 0. 1111 - val_n_outputs1_loss: 0. 0082Epoch 29/100175/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0630 - n_outputs0_loss: 0. 0571 - n_outputs1_loss: 0. 0060Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 1s - loss: 0. 1170 - n_outputs0_loss: 0. 1091 - n_outputs1_loss: 0. 0079Epoch 00029: val_loss did not improve from 0. 11585177/177 [==============================] - 7s 40ms/step - loss: 0. 0631 - n_outputs0_loss: 0. 0572 - n_outputs1_loss: 0. 0059 - val_loss: 0. 1170 - val_n_outputs0_loss: 0. 1091 - val_n_outputs1_loss: 0. 0079Epoch 00029: early stoppingTraining completed in 0:03:42. ----------- Best Eval Loss :0. 115850 ---------&lt;Figure size 640x480 with 1 Axes&gt;  Train your model&#182;:       !python /content/mycar/manage. py train --type rnn --model /content/mycar/models/mypilot. h5 --aug  using donkey v3. 1. 1 . . . loading config file: /content/mycar/config. pyloading personal config over-ridesconfig loadedsequence of images training&#34;get_model_by_type&#34; model Type is: rnnWARNING:tensorflow:From /usr/local/lib/python3. 6/dist-packages/tensorflow_core/python/ops/resource_variable_ops. py:1630: calling BaseResourceVariable. __init__ (from tensorflow. python. ops. resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:If using Keras pass *_constraint arguments to layers. Tub: /content/mycar/data/tubVaihingenIIICleaned200126 has 14234 recordscollating recordscollating sequencescollated 14169 sequences of length 6train: 11336, validation: 2833steps_per_epoch 177Epoch 1/100WARNING:tensorflow:From /usr/local/lib/python3. 6/dist-packages/tensorflow_core/python/ops/math_grad. py:1424: where (from tensorflow. python. ops. array_ops) is deprecated and will be removed in a future version. Instructions for updating:Use tf. where in 2. 0, which has the same broadcast rule as np. where2020-03-02 10:54:21. 132316: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcuda. so. 12020-03-02 10:54:21. 184607: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:21. 185259: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1618] Found device 0 with properties: name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1. 1135pciBusID: 0000:00:04. 02020-03-02 10:54:21. 198151: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudart. so. 10. 12020-03-02 10:54:21. 423175: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcublas. so. 102020-03-02 10:54:21. 552103: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcufft. so. 102020-03-02 10:54:21. 571738: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcurand. so. 102020-03-02 10:54:21. 843144: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusolver. so. 102020-03-02 10:54:21. 860870: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusparse. so. 102020-03-02 10:54:22. 395873: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudnn. so. 72020-03-02 10:54:22. 396042: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 396926: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 397639: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1746] Adding visible gpu devices: 02020-03-02 10:54:22. 399069: I tensorflow/core/platform/cpu_feature_guard. cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F2020-03-02 10:54:22. 437048: I tensorflow/core/platform/profile_utils/cpu_utils. cc:94] CPU Frequency: 2000160000 Hz2020-03-02 10:54:22. 437494: I tensorflow/compiler/xla/service/service. cc:168] XLA service 0x18fcf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:2020-03-02 10:54:22. 437537: I tensorflow/compiler/xla/service/service. cc:176]  StreamExecutor device (0): Host, Default Version2020-03-02 10:54:22. 612526: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 613280: I tensorflow/compiler/xla/service/service. cc:168] XLA service 0x18fdb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:2020-03-02 10:54:22. 613666: I tensorflow/compiler/xla/service/service. cc:176]  StreamExecutor device (0): Tesla P4, Compute Capability 6. 12020-03-02 10:54:22. 614994: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 615659: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1618] Found device 0 with properties: name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1. 1135pciBusID: 0000:00:04. 02020-03-02 10:54:22. 615753: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudart. so. 10. 12020-03-02 10:54:22. 616801: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcublas. so. 102020-03-02 10:54:22. 616847: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcufft. so. 102020-03-02 10:54:22. 616877: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcurand. so. 102020-03-02 10:54:22. 616901: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusolver. so. 102020-03-02 10:54:22. 616923: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcusparse. so. 102020-03-02 10:54:22. 616946: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudnn. so. 72020-03-02 10:54:22. 617032: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 617782: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 618298: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1746] Adding visible gpu devices: 02020-03-02 10:54:22. 621633: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudart. so. 10. 12020-03-02 10:54:22. 623067: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:2020-03-02 10:54:22. 623106: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1165]   0 2020-03-02 10:54:22. 623177: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1178] 0:  N 2020-03-02 10:54:22. 624514: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 625218: I tensorflow/stream_executor/cuda/cuda_gpu_executor. cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2020-03-02 10:54:22. 625802: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator. cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0. 2020-03-02 10:54:22. 625854: I tensorflow/core/common_runtime/gpu/gpu_device. cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -&gt; physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04. 0, compute capability: 6. 1)2020-03-02 10:54:30. 771371: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcublas. so. 102020-03-02 10:54:32. 314857: I tensorflow/stream_executor/platform/default/dso_loader. cc:44] Successfully opened dynamic library libcudnn. so. 7176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 3324Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 27s - loss: 0. 3010Epoch 00001: val_loss improved from inf to 0. 30102, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 80s 454ms/step - loss: 0. 3318 - val_loss: 0. 3010Epoch 2/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 3057Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 20s - loss: 0. 3038Epoch 00002: val_loss did not improve from 0. 30102177/177 [==============================] - 43s 242ms/step - loss: 0. 3062 - val_loss: 0. 3038Epoch 3/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 3042Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 15s - loss: 0. 2919Epoch 00003: val_loss improved from 0. 30102 to 0. 29193, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 41s 233ms/step - loss: 0. 3040 - val_loss: 0. 2919Epoch 4/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 2140Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 1228Epoch 00004: val_loss improved from 0. 29193 to 0. 12281, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 238ms/step - loss: 0. 2135 - val_loss: 0. 1228Epoch 5/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1206Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0975Epoch 00005: val_loss improved from 0. 12281 to 0. 09747, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 237ms/step - loss: 0. 1206 - val_loss: 0. 0975Epoch 6/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 1046Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 18s - loss: 0. 0939Epoch 00006: val_loss improved from 0. 09747 to 0. 09393, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 239ms/step - loss: 0. 1046 - val_loss: 0. 0939Epoch 7/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0984Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 15s - loss: 0. 0828Epoch 00007: val_loss improved from 0. 09393 to 0. 08277, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 236ms/step - loss: 0. 0984 - val_loss: 0. 0828Epoch 8/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0921Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0827Epoch 00008: val_loss improved from 0. 08277 to 0. 08269, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 236ms/step - loss: 0. 0921 - val_loss: 0. 0827Epoch 9/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0882Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0765Epoch 00009: val_loss improved from 0. 08269 to 0. 07652, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 239ms/step - loss: 0. 0881 - val_loss: 0. 0765Epoch 10/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0841Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0796Epoch 00010: val_loss did not improve from 0. 07652177/177 [==============================] - 42s 235ms/step - loss: 0. 0842 - val_loss: 0. 0796Epoch 11/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0806Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0780Epoch 00011: val_loss did not improve from 0. 07652177/177 [==============================] - 42s 235ms/step - loss: 0. 0807 - val_loss: 0. 0780Epoch 12/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0767Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0689Epoch 00012: val_loss improved from 0. 07652 to 0. 06885, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 239ms/step - loss: 0. 0766 - val_loss: 0. 0689Epoch 13/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0743Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0671Epoch 00013: val_loss improved from 0. 06885 to 0. 06709, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 238ms/step - loss: 0. 0743 - val_loss: 0. 0671Epoch 14/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0720Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 15s - loss: 0. 0648Epoch 00014: val_loss improved from 0. 06709 to 0. 06479, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 235ms/step - loss: 0. 0719 - val_loss: 0. 0648Epoch 15/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0705Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0607Epoch 00015: val_loss improved from 0. 06479 to 0. 06068, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 235ms/step - loss: 0. 0705 - val_loss: 0. 0607Epoch 16/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0669Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 15s - loss: 0. 0621Epoch 00016: val_loss did not improve from 0. 06068177/177 [==============================] - 41s 232ms/step - loss: 0. 0670 - val_loss: 0. 0621Epoch 17/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0650Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0604Epoch 00017: val_loss improved from 0. 06068 to 0. 06036, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 41s 234ms/step - loss: 0. 0650 - val_loss: 0. 0604Epoch 18/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0636Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0613Epoch 00018: val_loss did not improve from 0. 06036177/177 [==============================] - 42s 235ms/step - loss: 0. 0636 - val_loss: 0. 0613Epoch 19/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0605Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0585Epoch 00019: val_loss improved from 0. 06036 to 0. 05849, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 235ms/step - loss: 0. 0606 - val_loss: 0. 0585Epoch 20/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0586Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0557Epoch 00020: val_loss improved from 0. 05849 to 0. 05567, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 238ms/step - loss: 0. 0587 - val_loss: 0. 0557Epoch 21/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0573Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 18s - loss: 0. 0520Epoch 00021: val_loss improved from 0. 05567 to 0. 05205, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 239ms/step - loss: 0. 0575 - val_loss: 0. 0520Epoch 22/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0547Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0518Epoch 00022: val_loss improved from 0. 05205 to 0. 05184, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 237ms/step - loss: 0. 0547 - val_loss: 0. 0518Epoch 23/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0554Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0508Epoch 00023: val_loss improved from 0. 05184 to 0. 05078, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 235ms/step - loss: 0. 0553 - val_loss: 0. 0508Epoch 24/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0520Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0550Epoch 00024: val_loss did not improve from 0. 05078177/177 [==============================] - 42s 235ms/step - loss: 0. 0522 - val_loss: 0. 0550Epoch 25/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0513Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0483Epoch 00025: val_loss improved from 0. 05078 to 0. 04827, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 236ms/step - loss: 0. 0514 - val_loss: 0. 0483Epoch 26/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0499Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0502Epoch 00026: val_loss did not improve from 0. 04827177/177 [==============================] - 42s 235ms/step - loss: 0. 0497 - val_loss: 0. 0502Epoch 27/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0506Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0449Epoch 00027: val_loss improved from 0. 04827 to 0. 04485, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 236ms/step - loss: 0. 0506 - val_loss: 0. 0449Epoch 28/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0477Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0491Epoch 00028: val_loss did not improve from 0. 04485177/177 [==============================] - 42s 236ms/step - loss: 0. 0476 - val_loss: 0. 0491Epoch 29/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0470Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0508Epoch 00029: val_loss did not improve from 0. 04485177/177 [==============================] - 41s 234ms/step - loss: 0. 0471 - val_loss: 0. 0508Epoch 30/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0449Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0444Epoch 00030: val_loss improved from 0. 04485 to 0. 04441, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 238ms/step - loss: 0. 0448 - val_loss: 0. 0444Epoch 31/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0433Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0420Epoch 00031: val_loss improved from 0. 04441 to 0. 04200, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 237ms/step - loss: 0. 0433 - val_loss: 0. 0420Epoch 32/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0439Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0436Epoch 00032: val_loss did not improve from 0. 04200177/177 [==============================] - 41s 234ms/step - loss: 0. 0438 - val_loss: 0. 0436Epoch 33/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0429Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0443Epoch 00033: val_loss did not improve from 0. 04200177/177 [==============================] - 42s 235ms/step - loss: 0. 0430 - val_loss: 0. 0443Epoch 34/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0409Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0427Epoch 00034: val_loss did not improve from 0. 04200177/177 [==============================] - 42s 236ms/step - loss: 0. 0410 - val_loss: 0. 0427Epoch 35/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0419Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0433Epoch 00035: val_loss did not improve from 0. 04200177/177 [==============================] - 41s 234ms/step - loss: 0. 0418 - val_loss: 0. 0433Epoch 36/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0410Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0394Epoch 00036: val_loss improved from 0. 04200 to 0. 03945, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 235ms/step - loss: 0. 0409 - val_loss: 0. 0394Epoch 37/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0404Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0410Epoch 00037: val_loss did not improve from 0. 03945177/177 [==============================] - 42s 235ms/step - loss: 0. 0402 - val_loss: 0. 0410Epoch 38/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0401Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0385Epoch 00038: val_loss improved from 0. 03945 to 0. 03854, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 235ms/step - loss: 0. 0400 - val_loss: 0. 0385Epoch 39/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0379Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0397Epoch 00039: val_loss did not improve from 0. 03854177/177 [==============================] - 42s 235ms/step - loss: 0. 0381 - val_loss: 0. 0397Epoch 40/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0371Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0423Epoch 00040: val_loss did not improve from 0. 03854177/177 [==============================] - 42s 235ms/step - loss: 0. 0372 - val_loss: 0. 0423Epoch 41/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0369Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0421Epoch 00041: val_loss did not improve from 0. 03854177/177 [==============================] - 41s 234ms/step - loss: 0. 0370 - val_loss: 0. 0421Epoch 42/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0358Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0373Epoch 00042: val_loss improved from 0. 03854 to 0. 03727, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 236ms/step - loss: 0. 0358 - val_loss: 0. 0373Epoch 43/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0366Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0380Epoch 00043: val_loss did not improve from 0. 03727177/177 [==============================] - 41s 234ms/step - loss: 0. 0366 - val_loss: 0. 0380Epoch 44/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0355Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0401Epoch 00044: val_loss did not improve from 0. 03727177/177 [==============================] - 42s 235ms/step - loss: 0. 0355 - val_loss: 0. 0401Epoch 45/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0352Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0368Epoch 00045: val_loss improved from 0. 03727 to 0. 03677, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 238ms/step - loss: 0. 0352 - val_loss: 0. 0368Epoch 46/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0355Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0365Epoch 00046: val_loss improved from 0. 03677 to 0. 03652, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 235ms/step - loss: 0. 0356 - val_loss: 0. 0365Epoch 47/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0346Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 17s - loss: 0. 0405Epoch 00047: val_loss did not improve from 0. 03652177/177 [==============================] - 42s 236ms/step - loss: 0. 0346 - val_loss: 0. 0405Epoch 48/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0343Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0352Epoch 00048: val_loss improved from 0. 03652 to 0. 03524, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 237ms/step - loss: 0. 0343 - val_loss: 0. 0352Epoch 49/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0328Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 18s - loss: 0. 0353Epoch 00049: val_loss did not improve from 0. 03524177/177 [==============================] - 42s 238ms/step - loss: 0. 0329 - val_loss: 0. 0353Epoch 50/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0332Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 15s - loss: 0. 0392Epoch 00050: val_loss did not improve from 0. 03524177/177 [==============================] - 42s 235ms/step - loss: 0. 0331 - val_loss: 0. 0392Epoch 51/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0322Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 15s - loss: 0. 0351Epoch 00051: val_loss improved from 0. 03524 to 0. 03511, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 41s 233ms/step - loss: 0. 0322 - val_loss: 0. 0351Epoch 52/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0311Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0355Epoch 00052: val_loss did not improve from 0. 03511177/177 [==============================] - 41s 233ms/step - loss: 0. 0311 - val_loss: 0. 0355Epoch 53/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0316Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0334Epoch 00053: val_loss improved from 0. 03511 to 0. 03341, saving model to /content/mycar/models/mypilot. h5177/177 [==============================] - 42s 234ms/step - loss: 0. 0317 - val_loss: 0. 0334Epoch 54/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0313Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0343Epoch 00054: val_loss did not improve from 0. 03341177/177 [==============================] - 41s 233ms/step - loss: 0. 0313 - val_loss: 0. 0343Epoch 55/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0313Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0354Epoch 00055: val_loss did not improve from 0. 03341177/177 [==============================] - 42s 235ms/step - loss: 0. 0314 - val_loss: 0. 0354Epoch 56/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0303Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0353Epoch 00056: val_loss did not improve from 0. 03341177/177 [==============================] - 42s 235ms/step - loss: 0. 0304 - val_loss: 0. 0353Epoch 57/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0312Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0344Epoch 00057: val_loss did not improve from 0. 03341177/177 [==============================] - 41s 234ms/step - loss: 0. 0312 - val_loss: 0. 0344Epoch 58/100176/177 [============================&gt;. ] - ETA: 0s - loss: 0. 0316Epoch 1/100 44/177 [======&gt;. . . . . . . . . . . . . . . . . . . . . . . ] - ETA: 16s - loss: 0. 0341Epoch 00058: val_loss did not improve from 0. 03341177/177 [==============================] - 41s 234ms/step - loss: 0. 0316 - val_loss: 0. 0341Epoch 00058: early stoppingTraining completed in 0:40:58. ----------- Best Eval Loss :0. 033409 ---------&lt;Figure size 640x480 with 1 Axes&gt;  Check if the model is generated       %cd /content/mycar/modelsfile = glob. glob(&quot;*. png&quot;)Image(file[0])  /content/mycar/models  Copy the trained model back to Donkey Car (Pi)&#182;: Once the training is complete on Colab, download mypilot. h5 file from /content/mycar/models/ myconfig. py file from /content/mycar/      from google. colab import filesfiles. download(&#39;. /mypilot. h5&#39;)%cd /content/mycarfiles. download(&#39;myconfig. py&#39;)  /content/mycar  Alternatively, you can copy the model back to Google Drive too       !cp /content/mycar/models/mypilot. h5 /content/drive/My\ Drive/myCar/mypilot. h5    Copy the file from your PC or Mac to the Raspberry Pi using Filezilla or scp command. &#182;: sftp pi@raspberry. localcd mycar/modelsput mypilot. h5Start Autopilot on Pi&#182;: cd ~/mycarpython manage. py drive --model models/mypilot. h5 --jsBonus - Salient Object Visualization&#182;:     Note: It seems like the salient mode doesn&#8217;t work for RNN networks       # !pip install git+https://github. com/autorope/keras-vis. git!pip uninstall keras-vis!pip install git+https://github. com/sctse999/keras-vis    Uninstalling keras-vis-0. 4. 1: Would remove:  /usr/local/lib/python3. 6/dist-packages/docs/*  /usr/local/lib/python3. 6/dist-packages/keras_vis-0. 4. 1. dist-info/*  /usr/local/lib/python3. 6/dist-packages/vis/* Would not remove (might be manually added):  /usr/local/lib/python3. 6/dist-packages/docs/autogen. py  /usr/local/lib/python3. 6/dist-packages/docs/structure. pyProceed (y/n)? y Successfully uninstalled keras-vis-0. 4. 1Collecting git+https://github. com/sctse999/keras-vis Cloning https://github. com/sctse999/keras-vis to /tmp/pip-req-build-fppmjn_o Running command git clone -q https://github. com/sctse999/keras-vis /tmp/pip-req-build-fppmjn_oRequirement already satisfied: six in /usr/local/lib/python3. 6/dist-packages (from keras-vis==0. 5. 0) (1. 12. 0)Requirement already satisfied: scikit-image in /usr/local/lib/python3. 6/dist-packages (from keras-vis==0. 5. 0) (0. 16. 2)Requirement already satisfied: matplotlib in /usr/local/lib/python3. 6/dist-packages (from keras-vis==0. 5. 0) (3. 1. 3)Requirement already satisfied: h5py in /usr/local/lib/python3. 6/dist-packages (from keras-vis==0. 5. 0) (2. 8. 0)Requirement already satisfied: networkx&gt;=2. 0 in /usr/local/lib/python3. 6/dist-packages (from scikit-image-&gt;keras-vis==0. 5. 0) (2. 4)Requirement already satisfied: pillow&gt;=4. 3. 0 in /usr/local/lib/python3. 6/dist-packages (from scikit-image-&gt;keras-vis==0. 5. 0) (6. 2. 2)Requirement already satisfied: imageio&gt;=2. 3. 0 in /usr/local/lib/python3. 6/dist-packages (from scikit-image-&gt;keras-vis==0. 5. 0) (2. 4. 1)Requirement already satisfied: PyWavelets&gt;=0. 4. 0 in /usr/local/lib/python3. 6/dist-packages (from scikit-image-&gt;keras-vis==0. 5. 0) (1. 1. 1)Requirement already satisfied: scipy&gt;=0. 19. 0 in /usr/local/lib/python3. 6/dist-packages (from scikit-image-&gt;keras-vis==0. 5. 0) (1. 4. 1)Requirement already satisfied: cycler&gt;=0. 10 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;keras-vis==0. 5. 0) (0. 10. 0)Requirement already satisfied: pyparsing!=2. 0. 4,!=2. 1. 2,!=2. 1. 6,&gt;=2. 0. 1 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;keras-vis==0. 5. 0) (2. 4. 6)Requirement already satisfied: kiwisolver&gt;=1. 0. 1 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;keras-vis==0. 5. 0) (1. 1. 0)Requirement already satisfied: numpy&gt;=1. 11 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;keras-vis==0. 5. 0) (1. 17. 5)Requirement already satisfied: python-dateutil&gt;=2. 1 in /usr/local/lib/python3. 6/dist-packages (from matplotlib-&gt;keras-vis==0. 5. 0) (2. 6. 1)Requirement already satisfied: decorator&gt;=4. 3. 0 in /usr/local/lib/python3. 6/dist-packages (from networkx&gt;=2. 0-&gt;scikit-image-&gt;keras-vis==0. 5. 0) (4. 4. 1)Requirement already satisfied: setuptools in /usr/local/lib/python3. 6/dist-packages (from kiwisolver&gt;=1. 0. 1-&gt;matplotlib-&gt;keras-vis==0. 5. 0) (45. 1. 0)Building wheels for collected packages: keras-vis Building wheel for keras-vis (setup. py) . . . done Created wheel for keras-vis: filename=keras_vis-0. 5. 0-py2. py3-none-any. whl size=38989 sha256=3425b80d2a4c02e113e49cc0eac6273520739475597a75c838d65a26dba7950b Stored in directory: /tmp/pip-ephem-wheel-cache-5ih_t8yg/wheels/29/87/8e/abd2257f08391eabe7552711aecf08cbb50f79877210b21be0Successfully built keras-visInstalling collected packages: keras-visSuccessfully installed keras-vis-0. 5. 0        %cd /content/mycar!donkey makemovie --tub data/{tub_name} --model models/mypilot. h5 --type linear --salient    Download the movie to local machine       %cd /content/mycar!ls -ahlfiles. download(&#39;tub_movie. mp4&#39;)  /content/mycartotal 89Mdrwxr-xr-x 6 root root 4. 0K Mar 2 11:48 . drwxr-xr-x 1 root root 4. 0K Mar 2 10:52 . . -rw-r--r-- 1 root root 13K Mar 2 10:51 config. pydrwxr-xr-x 3 root root 4. 0K Mar 2 10:52 datadrwxr-xr-x 2 root root 4. 0K Mar 2 10:51 logs-rw-r--r-- 1 root root 23K Mar 2 10:51 manage. pydrwxr-xr-x 2 root root 4. 0K Mar 2 11:35 models-rw-r--r-- 1 root root 14K Mar 2 10:52 myconfig. py-rw-r--r-- 1 root root 1. 8M Mar 2 11:46 mypilot. h5drwxr-xr-x 2 root root 4. 0K Mar 2 10:54 __pycache__-rw-r--r-- 1 root root 39K Mar 2 10:51 train. py-rw-r--r-- 1 root root 39M Mar 2 11:50 tub_movie. mp4-rw------- 1 root root 49M Mar 2 11:46 tubVaihingenIIICleaned200126. tar. gz  Or download the file to Google Drive       !cp /content/mycar/tub_movie. mp4 /content/drive/My\ Drive/myCar/tub_movie. mp4    "
    }, {
    "id": 5,
    "url": "https://uwesterr.github.io/fastpages/github/jupyter%20notebook/vs%20code/colab/2020/03/01/ColabGuide.html",
    "title": "Working with fastpages, GitHub and Colab",
    "body": "2020/03/01 - The idea is to work with Jupyter Notebook in Colab, the notebook is part of a Fastpages blog and should be edited either in Colab or VS Code  write a Blog in Fastpages format of Blog is Jupyter Notebook run the Notebook in Colab also edit in VS Code is necessary     use Git to synchronize GitHub repo with VS Code local copy   Write a blog with Fastpages: A detailed instruction on how to write Fastpage blogs is given at  for juypter notebooks  for markdownWorking with notebook in Colab: Once the blog is opened there are buttons  View on GitHub The Jupyter Notbeook file is opened in the GitHub environment Open in Colab The Jupyter Notbeook file is opened in the Colab environmentIn the Colab environment the file can be run with GPU support. An intro to Colab is given here To save the changes chose under “File” the option “Save a copy in GitHub” as shown below Colab will open a dialog as shown belowIt might be that it asks for your GitHub credentials before opening the dialog Working with VS Code: To work with the Fastpages blog clone the repository as described here It is then easy to synchronize with GitHub, note, don’t forget to pull the repo once you saved a notebook version from Colab to GitHub. Avoid conflicting versions: If you do the following  Change file in Colab Save to GitHub Change same file in VS Try to pushYou will have *conflicts in the file** and need command line magic to solve the issue. I ended up setting the whole blog up from scratch. Better: use Git: Snyc which does a Git: Pull first and then a Git: Push "
    }, {
    "id": 6,
    "url": "https://uwesterr.github.io/jupyter/2020/02/20/test.html",
    "title": "Fastpages Notebook Blog Post",
    "body": "2020/02/20 -           About&#182;This notebook is a demonstration of some of capabilities of fastpages with notebooks. With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! Front Matter&#182;: Front Matter is a markdown cell at the beginning of your notebook that allows you to inject metadata into your notebook. For example: Setting toc: true will automatically generate a table of contentsSetting badges: true will automatically include GitHub and Google Colab links to your notebook. Setting comments: true will enable commenting on your blog post, powered by utterances. More details and options for front matter can be viewed on the front matter section of the README. Markdown Shortcuts&#182;: A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. A #hide_input comment at the top of any code cell will only hide the input of that cell.     The comment #hide_input was used to hide the code that produced this.   put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it:              #collapse-hideimport pandas as pdimport altair as alt       put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it:              #collapse-showcars = &#39;https://vega. github. io/vega-datasets/data/cars. json&#39;movies = &#39;https://vega. github. io/vega-datasets/data/movies. json&#39;sp500 = &#39;https://vega. github. io/vega-datasets/data/sp500. csv&#39;stocks = &#39;https://vega. github. io/vega-datasets/data/stocks. csv&#39;flights = &#39;https://vega. github. io/vega-datasets/data/flights-5k. json&#39;       Interactive Charts With Altair&#182;: Charts made with Altair remain interactive.  Example charts taken from this repo, specifically this notebook. Example 1: DropDown&#182;:       # single-value selection over [Major_Genre, MPAA_Rating] pairs# use specific hard-wired values as the initial selected valuesselection = alt. selection_single(  name=&#39;Select&#39;,  fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;],  init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;},  bind={&#39;Major_Genre&#39;: alt. binding_select(options=genres), &#39;MPAA_Rating&#39;: alt. binding_radio(options=mpaa)}) # scatter plot, modify opacity based on selectionalt. Chart(movies). mark_circle(). add_selection(  selection). encode(  x=&#39;Rotten_Tomatoes_Rating:Q&#39;,  y=&#39;IMDB_Rating:Q&#39;,  tooltip=&#39;Title:N&#39;,  opacity=alt. condition(selection, alt. value(0. 75), alt. value(0. 05)))    Example 2: Tooltips&#182;:       alt. Chart(movies). mark_circle(). add_selection(  alt. selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;])). encode(  x=&#39;Rotten_Tomatoes_Rating:Q&#39;,  y=alt. Y(&#39;IMDB_Rating:Q&#39;, axis=alt. Axis(minExtent=30)), # use min extent to stabilize axis title placement  tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;]). properties(  width=600,  height=400)    Example 3: More Tooltips&#182;:       # select a point for which to provide details-on-demandlabel = alt. selection_single(  encodings=[&#39;x&#39;], # limit selection to x-axis value  on=&#39;mouseover&#39;, # select on mouseover events  nearest=True,  # select data point nearest the cursor  empty=&#39;none&#39;   # empty selection includes no data points)# define our base line chart of stock pricesbase = alt. Chart(). mark_line(). encode(  alt. X(&#39;date:T&#39;),  alt. Y(&#39;price:Q&#39;, scale=alt. Scale(type=&#39;log&#39;)),  alt. Color(&#39;symbol:N&#39;))alt. layer(  base, # base line chart    # add a rule mark to serve as a guide line  alt. Chart(). mark_rule(color=&#39;#aaa&#39;). encode(    x=&#39;date:T&#39;  ). transform_filter(label),    # add circle marks for selected time points, hide unselected points  base. mark_circle(). encode(    opacity=alt. condition(label, alt. value(1), alt. value(0))  ). add_selection(label),  # add white stroked text to provide a legible background for labels  base. mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2). encode(    text=&#39;price:Q&#39;  ). transform_filter(label),  # add text labels for stock prices  base. mark_text(align=&#39;left&#39;, dx=5, dy=-5). encode(    text=&#39;price:Q&#39;  ). transform_filter(label),    data=stocks). properties(  width=700,  height=400)    Data Tables&#182;: You can display tables per the usual way in your blog:       movies = &#39;https://vega. github. io/vega-datasets/data/movies. json&#39;df = pd. read_json(movies)# display table with pandasdf[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;,   &#39;Production_Budget&#39;, &#39;IMDB_Rating&#39;]]. head()           Title   Worldwide_Gross   Production_Budget   IMDB_Rating         0   The Land Girls   146083. 0   8000000. 0   6. 1       1   First Love, Last Rites   10876. 0   300000. 0   6. 9       2   I Married a Strange Person   203134. 0   250000. 0   6. 8       3   Let's Talk About Sex   373615. 0   300000. 0   NaN       4   Slam   1087521. 0   1000000. 0   3. 4     Images&#182;: Local Images&#182;: You can reference local images and they will be copied and rendered on your blog automatically.  You can include these with the following markdown syntax: ![](my_icons/fastai_logo. png) Remote Images&#182;: Remote images can be included with the following markdown syntax: ![](https://image. flaticon. com/icons/svg/36/36686. svg) Animated Gifs&#182;: Animated Gifs work, too! ![](https://upload. wikimedia. org/wikipedia/commons/7/71/ChessPawnSpecialMoves. gif) Captions&#182;: You can include captions with markdown images like this: ![](https://www. fast. ai/images/fastai_paper/show_batch. png  Credit: https://www. fast. ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/ ) Other Elements&#182;Tweetcards&#182;: Typing &gt; twitter: https://twitter. com/jakevdp/status/1204765621767901185?s=20 will render this:  Altair 4. 0 is released! https://t. co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t. co/roXmzcsT58 . . . read on for some highlights. pic. twitter. com/vWJ0ZveKbZ &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Youtube Videos&#182;: Typing &gt; youtube: https://youtu. be/XfoYk_Z5AkI will render this:   Boxes / Callouts&#182;: Typing &gt; Warning: There will be no second warning! will render this:    Warning: There will be no second warning! Typing &gt; Important: Pay attention! It's important. will render this:    Important: Pay attention! It&#8217;s important. Typing &gt; Tip: This is my tip. will render this:    Tip: This is my tip. Typing &gt; Note: Take note of this. will render this:    Note: Take note of this. Typing &gt; Note: A doc link to [an example website: fast. ai](https://www. fast. ai/) should also work fine. will render in the docs:    Note: A doc link to an example website: fast. ai should also work fine. Footnotes&#182;: You can have footnotes in notebooks just like you can with markdown. For example, here is a footnote 1. This is the footnote. &#8617; "
    }, {
    "id": 7,
    "url": "https://uwesterr.github.io/markdown/2020/01/14/test-markdown-post.html",
    "title": "Example Markdown Post",
    "body": "2020/01/14 - Basic setup: Jekyll requires blog post files to be named according to the following format: YEAR-MONTH-DAY-filename. md Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. . md is the file extension for markdown files. The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. Basic formatting: You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: Lists: Here’s a list:  item 1 item 2And a numbered list:  item 1 item 2Boxes and stuff:  This is a quotation    You can include alert boxes…and…    You can include info boxesImages: Code: You can format text and code per usual General preformatted text: # Do a thingdo_thing()Python code and output: # Prints '2'print(1+1)2Formatting text as shell commands: echo  hello world . /some_script. sh --option  value wget https://example. com/cat_photo1. pngFormatting text as YAML: key: value- another_key:  another value Tables:       Column 1   Column 2         A thing   Another thing   Tweetcards: Altair 4. 0 is released! https://t. co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t. co/roXmzcsT58 . . . read on for some highlights. pic. twitter. com/vWJ0ZveKbZ &mdash; Jake VanderPlas (@jakevdp) December 11, 2019Footnotes:       This is the footnote.  &#8617;    "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')
    this.metadataWhitelist = ['position']

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}