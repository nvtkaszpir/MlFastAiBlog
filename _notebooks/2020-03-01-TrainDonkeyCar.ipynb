{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Donkey Car Training  modified using Google Colab",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "source": [
        "# Train donkeycar with GPU support in Colab\n",
        "> Use Colab to train a neural network for a donkey car \n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- categories: [donkeycar, Colab]\n",
        "- image: images/roboCar2020.jpg\n",
        "- author: Uwe Sterr\n",
        "- comments: true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fg2cbgwvj86i"
      },
      "source": [
        "# Credit\n",
        "> Note: This notebook is based on https://colab.research.google.com/github/robocarstore/donkey-car-training-on-google-colab/blob/master/Donkey_Car_Training_using_Google_Colab.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "arsH-DhLcihq"
      },
      "source": [
        "## Check GPU allocation\n",
        "If \"Found GPU at: / device: GPU: 0\" is displayed, the GPU is ready to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBVjteqHtvg-",
        "colab_type": "text"
      },
      "source": [
        "> Note: Donkeycar at the time of writing in March 2020 uses Tensorflow 1.13, therefore version 1.xx is installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQgEhuoTcg0N",
        "outputId": "16ddcae0-d63f-4d37-d465-e38a8a821ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#collapse-show \n",
        "%tensorflow_version 1.13.1\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.13.1`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ba2oPDIrsDFg"
      },
      "source": [
        "## Git Clone the donkey repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGlk1n7OtvhE",
        "colab_type": "text"
      },
      "source": [
        "Get the latest donkeycar from GitHub \n",
        "> Note: The default branch is \"dev\", however, the documentation is for the master branch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oOxd9PFUyNxI",
        "outputId": "ace7b595-9b0a-438c-a218-e18e63293932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!git clone https://github.com/autorope/donkeycar.git \n",
        "%cd /content/donkeycar\n",
        "\n",
        "!git checkout master"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'donkeycar'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/146)\u001b[K\rremote: Counting objects:   1% (2/146)\u001b[K\rremote: Counting objects:   2% (3/146)\u001b[K\rremote: Counting objects:   3% (5/146)\u001b[K\rremote: Counting objects:   4% (6/146)\u001b[K\rremote: Counting objects:   5% (8/146)\u001b[K\rremote: Counting objects:   6% (9/146)\u001b[K\rremote: Counting objects:   7% (11/146)\u001b[K\rremote: Counting objects:   8% (12/146)\u001b[K\rremote: Counting objects:   9% (14/146)\u001b[K\rremote: Counting objects:  10% (15/146)\u001b[K\rremote: Counting objects:  11% (17/146)\u001b[K\rremote: Counting objects:  12% (18/146)\u001b[K\rremote: Counting objects:  13% (19/146)\u001b[K\rremote: Counting objects:  14% (21/146)\u001b[K\rremote: Counting objects:  15% (22/146)\u001b[K\rremote: Counting objects:  16% (24/146)\u001b[K\rremote: Counting objects:  17% (25/146)\u001b[K\rremote: Counting objects:  18% (27/146)\u001b[K\rremote: Counting objects:  19% (28/146)\u001b[K\rremote: Counting objects:  20% (30/146)\u001b[K\rremote: Counting objects:  21% (31/146)\u001b[K\rremote: Counting objects:  22% (33/146)\u001b[K\rremote: Counting objects:  23% (34/146)\u001b[K\rremote: Counting objects:  24% (36/146)\u001b[K\rremote: Counting objects:  25% (37/146)\u001b[K\rremote: Counting objects:  26% (38/146)\u001b[K\rremote: Counting objects:  27% (40/146)\u001b[K\rremote: Counting objects:  28% (41/146)\u001b[K\rremote: Counting objects:  29% (43/146)\u001b[K\rremote: Counting objects:  30% (44/146)\u001b[K\rremote: Counting objects:  31% (46/146)\u001b[K\rremote: Counting objects:  32% (47/146)\u001b[K\rremote: Counting objects:  33% (49/146)\u001b[K\rremote: Counting objects:  34% (50/146)\u001b[K\rremote: Counting objects:  35% (52/146)\u001b[K\rremote: Counting objects:  36% (53/146)\u001b[K\rremote: Counting objects:  37% (55/146)\u001b[K\rremote: Counting objects:  38% (56/146)\u001b[K\rremote: Counting objects:  39% (57/146)\u001b[K\rremote: Counting objects:  40% (59/146)\u001b[K\rremote: Counting objects:  41% (60/146)\u001b[K\rremote: Counting objects:  42% (62/146)\u001b[K\rremote: Counting objects:  43% (63/146)\u001b[K\rremote: Counting objects:  44% (65/146)\u001b[K\rremote: Counting objects:  45% (66/146)\u001b[K\rremote: Counting objects:  46% (68/146)\u001b[K\rremote: Counting objects:  47% (69/146)\u001b[K\rremote: Counting objects:  48% (71/146)\u001b[K\rremote: Counting objects:  49% (72/146)\u001b[K\rremote: Counting objects:  50% (73/146)\u001b[K\rremote: Counting objects:  51% (75/146)\u001b[K\rremote: Counting objects:  52% (76/146)\u001b[K\rremote: Counting objects:  53% (78/146)\u001b[K\rremote: Counting objects:  54% (79/146)\u001b[K\rremote: Counting objects:  55% (81/146)\u001b[K\rremote: Counting objects:  56% (82/146)\u001b[K\rremote: Counting objects:  57% (84/146)\u001b[K\rremote: Counting objects:  58% (85/146)\u001b[K\rremote: Counting objects:  59% (87/146)\u001b[K\rremote: Counting objects:  60% (88/146)\u001b[K\rremote: Counting objects:  61% (90/146)\u001b[K\rremote: Counting objects:  62% (91/146)\u001b[K\rremote: Counting objects:  63% (92/146)\u001b[K\rremote: Counting objects:  64% (94/146)\u001b[K\rremote: Counting objects:  65% (95/146)\u001b[K\rremote: Counting objects:  66% (97/146)\u001b[K\rremote: Counting objects:  67% (98/146)\u001b[K\rremote: Counting objects:  68% (100/146)\u001b[K\rremote: Counting objects:  69% (101/146)\u001b[K\rremote: Counting objects:  70% (103/146)\u001b[K\rremote: Counting objects:  71% (104/146)\u001b[K\rremote: Counting objects:  72% (106/146)\u001b[K\rremote: Counting objects:  73% (107/146)\u001b[K\rremote: Counting objects:  74% (109/146)\u001b[K\rremote: Counting objects:  75% (110/146)\u001b[K\rremote: Counting objects:  76% (111/146)\u001b[K\rremote: Counting objects:  77% (113/146)\u001b[K\rremote: Counting objects:  78% (114/146)\u001b[K\rremote: Counting objects:  79% (116/146)\u001b[K\rremote: Counting objects:  80% (117/146)\u001b[K\rremote: Counting objects:  81% (119/146)\u001b[K\rremote: Counting objects:  82% (120/146)\u001b[K\rremote: Counting objects:  83% (122/146)\u001b[K\rremote: Counting objects:  84% (123/146)\u001b[K\rremote: Counting objects:  85% (125/146)\u001b[K\rremote: Counting objects:  86% (126/146)\u001b[K\rremote: Counting objects:  87% (128/146)\u001b[K\rremote: Counting objects:  88% (129/146)\u001b[K\rremote: Counting objects:  89% (130/146)\u001b[K\rremote: Counting objects:  90% (132/146)\u001b[K\rremote: Counting objects:  91% (133/146)\u001b[K\rremote: Counting objects:  92% (135/146)\u001b[K\rremote: Counting objects:  93% (136/146)\u001b[K\rremote: Counting objects:  94% (138/146)\u001b[K\rremote: Counting objects:  95% (139/146)\u001b[K\rremote: Counting objects:  96% (141/146)\u001b[K\rremote: Counting objects:  97% (142/146)\u001b[K\rremote: Counting objects:  98% (144/146)\u001b[K\rremote: Counting objects:  99% (145/146)\u001b[K\rremote: Counting objects: 100% (146/146)\u001b[K\rremote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 12082 (delta 57), reused 130 (delta 47), pack-reused 11936\u001b[K\n",
            "Receiving objects: 100% (12082/12082), 65.18 MiB | 29.06 MiB/s, done.\n",
            "Resolving deltas: 100% (7548/7548), done.\n",
            "/content/donkeycar\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Switched to a new branch 'master'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9TkkcF-gsAnx"
      },
      "source": [
        "## Install donkey car\n",
        "Different to the description at http://docs.donkeycar.com/guide/host_pc/setup_ubuntu/ we create no anaconda environment since the script is supposed to run on Colab which will delete the instance anyway"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jz_PZgrByPDh",
        "outputId": "20c4cef4-f77b-48c3-b26b-3b71de487a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "!pip3 install -e .[pc]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/donkeycar\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (1.17.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (6.2.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.6.2)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (4.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (2.8.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.2.3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.25.3)\n",
            "Requirement already satisfied: PrettyTable in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (0.7.2)\n",
            "Collecting paho-mqtt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/11/1dd5c70f0f27a88a3a05772cd95f6087ac479fac66d9c7752ee5e16ddbbc/paho-mqtt-1.5.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.1) (3.1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.1) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->donkeycar==3.1.1) (1.12.0)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.1) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.1) (4.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.1) (4.28.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.1) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->donkeycar==3.1.1) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->donkeycar==3.1.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->donkeycar==3.1.1) (2.4.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->donkeycar==3.1.1) (45.1.0)\n",
            "Building wheels for collected packages: paho-mqtt\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.5.0-cp36-none-any.whl size=61416 sha256=47fecced95422f3f8c63e74f832a05698c847da857f7ea0d9edc18cba1d7875f\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/94/6c/8474137cb7a5a3e001d70a22c8ff919caee69435376bccce79\n",
            "Successfully built paho-mqtt\n",
            "Installing collected packages: paho-mqtt, donkeycar\n",
            "  Running setup.py develop for donkeycar\n",
            "Successfully installed donkeycar paho-mqtt-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "syCctLq2r4Wk"
      },
      "source": [
        "## Create Project\n",
        "In this step the follwoing actions take place\n",
        "- create necessary folders (models, data, logs)\n",
        "- copying necessary files into folders (manage.py, myconfig.py etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xjJBSITyXy2",
        "outputId": "bf479368-d46f-4fab-8efe-483f37aa971d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!donkey createcar --path /content/mycar"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.1 ...\n",
            "Creating car folder: /content/mycar\n",
            "making dir  /content/mycar\n",
            "Creating data & model folders.\n",
            "making dir  /content/mycar/models\n",
            "making dir  /content/mycar/data\n",
            "making dir  /content/mycar/logs\n",
            "Copying car application template: complete\n",
            "Copying car config defaults. Adjust these before starting your car.\n",
            "Copying train script. Adjust these before starting your car.\n",
            "Copying my car config overrides\n",
            "Donkey setup complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SCf6uTHnO4Lh"
      },
      "source": [
        "## Prepare Data\n",
        "In order to train the neural network we need to supply trainings data which are recorded on the pi during driving the donkeycar on the track\n",
        "\n",
        "### Copy the following code and run on pi \n",
        "> Note: Copying of the data is much faster if the data is zipped to one file.\n",
        "\n",
        "```bash\n",
        "cd ~/mycar/data\n",
        "tar -czf tub_xx_yyyy_mm_dd.tar.gz tub_xx_yyyy_mm_dd\n",
        "\n",
        "```\n",
        "\n",
        "This will create a tub_xx_yyyy_mm_dd.tar.gz file under ~/mycar/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dnUy1Z1zro77"
      },
      "source": [
        "## Upload Data\n",
        "\n",
        "\n",
        "### Copy the tub to your local pc\n",
        "\n",
        "Run this on your local pc if you are using linux/mac\n",
        "```\n",
        "sftp pi@raspberry.local\n",
        "cd ~/mycar/data\n",
        "get tub_xx_yyyy_mm_dd.tar.gz\n",
        "```\n",
        "\n",
        "If you are on a windows, download sftp utility like [filezilla](https://filezilla-project.org/) or [putty](https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlwZuLKA56nt"
      },
      "source": [
        "### Define your tub name here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0ShFSsaewLCT",
        "colab": {}
      },
      "source": [
        "tub_name=\"tubVaihingenIIICleaned200126\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W47gmXA0O4Lo"
      },
      "source": [
        "### Upload the tub to Google Drive\n",
        "\n",
        "First upload the tub_x_yyyy_mm_dd.tar.gz to Google Drive. We will then mount Google Drive from colab and copy the data from Drive directly. \n",
        "> Note: To copy data from Google Drive to Colab is faster than uplaoding it from local machine.  \n",
        "\n",
        "When you run the cell below, you will need to click the link and generate an authorization code to for colab to access your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bgp_wtENw_4n",
        "outputId": "dda42561-1c80-47a9-d670-a8a6c97585d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IfSDpXj9x16v"
      },
      "source": [
        "Suppose you upload the tub_xx_yyyy_mm_dd.tar.gz to Google Drive/mycar/tub_xx_yyyy_mm_dd.tar.gz, this is how you copy it from Google Drive to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BIzWTrV-xwkJ",
        "outputId": "246f5b35-7dd6-46ee-e1bb-bf013bed0c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd /content/mycar\n",
        "!rm -rf data\n",
        "!mkdir data\n",
        "%cd /content/mycar/data\n",
        "!cp /content/drive/My\\ Drive/myCar/{tub_name}.tar.gz ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar\n",
            "/content/mycar/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIdS-AyIxn6e",
        "colab_type": "text"
      },
      "source": [
        "## Upload local files\n",
        "You can upload files from local machine as well, but probably is slower than above approach downloading files from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsHJGimwxv4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j4ABM1_VSgOF"
      },
      "source": [
        "#### Get myconfig.py\n",
        "> Note: In `myconfig.py` therer are parameters which control the training such as: \n",
        " \n",
        "\n",
        "```\n",
        "\n",
        " line parameter --type to the python manage.py train and drive commands.\n",
        "\n",
        " DEFAULT_MODEL_TYPE = 'linear'   (linear|categorical|rnn|imu|behavior|3d|localizer|latent)\n",
        "\n",
        " BATCH_SIZE = 128                how many records to use when doing one pass of gradient decent. Use a smaller number if your gpu is running out of memory.\n",
        "\n",
        " TRAIN_TEST_SPLIT = 0.8          what percent of records to use for training. the remaining used for validation.\n",
        "\n",
        " MAX_EPOCHS = 100                how many times to visit all records of your data\n",
        "\n",
        " SHOW_PLOT = True                would you like to see a pop up display of final loss?\n",
        "\n",
        " VEBOSE_TRAIN = True             would you like to see a progress bar with text during training?\n",
        "\n",
        " USE_EARLY_STOP = True           would you like to stop the training if we see it's not improving fit?\n",
        "\n",
        " EARLY_STOP_PATIENCE = 5         how many epochs to wait before no improvement\n",
        "\n",
        " MIN_DELTA = .0005               early stop will want this much loss change before calling it improved.\n",
        "\n",
        " PRINT_MODEL_SUMMARY = True      print layers and weights to stdout\n",
        "\n",
        " OPTIMIZER = None                adam, sgd, rmsprop, etc.. None accepts default\n",
        "\n",
        " LEARNING_RATE = 0.001           only used when OPTIMIZER specified\n",
        "\n",
        " LEARNING_RATE_DECAY = 0.0       only used when OPTIMIZER specified\n",
        "\n",
        " SEND_BEST_MODEL_TO_PI = False   change to true to automatically send best model during training\n",
        "\n",
        " CACHE_IMAGES = True             keep images in memory. will speed succesive epochs, but crater if not enough mem.\n",
        "\n",
        " \n",
        "\n",
        " PRUNE_CNN = False               This will remove weights from your model. The primary goal is to increase performance.\n",
        "\n",
        " PRUNE_PERCENT_TARGET = 75        The desired percentage of pruning.\n",
        "\n",
        " PRUNE_PERCENT_PER_ITERATION = 20  Percenge of pruning that is perform per iteration.\n",
        "\n",
        " PRUNE_VAL_LOSS_DEGRADATION_LIMIT = 0.2  The max amout of validation loss that is permitted during pruning.\n",
        "\n",
        " PRUNE_EVAL_PERCENT_OF_DATASET = .05   percent of dataset used to perform evaluation of model.\n",
        "RNN or 3D  \n",
        "SEQUENCE_LENGTH = 3             #some models use a number of images over time. This controls how many.  \n",
        "\n",
        "# # Region of interst cropping\n",
        "# # only supported in Categorical and Linear models.\n",
        "ROI_CROP_TOP = 0                    #the number of rows of pixels to ignore on the top of the image  \n",
        " ROI_CROP_BOTTOM = 0            #the number of rows of pixels to ignore on the bottom of the image \n",
        "```\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qO5y5QlHSdWB",
        "outputId": "49cbf22c-3646-4048-f62e-e8d22c4ba182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/mycar\n",
        "!cp /content/drive/My\\ Drive/myCar/myconfig.py ."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wbv-bEt-v_IC"
      },
      "source": [
        "### Upload pre-trained model\n",
        "Upload model in case you want to use a pre-trained model for transfer learning.\n",
        "To define which layers shall be trained and which shall be frozen set the parameters in `myconfig.py``\n",
        "\n",
        "Model transfer options\n",
        "\n",
        " When copying weights during a model transfer operation, should we freeze a certain number of layers\n",
        "\n",
        " to the incoming weights and not allow them to change during training?\n",
        "\n",
        "```\n",
        "FREEZE_LAYERS = False               #default False will allow all layers to be modified by training\n",
        "NUM_LAST_LAYERS_TO_TRAIN = 7        #when freezing layers, how many layers from the last should be allowed to train?\n",
        "\n",
        " ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UxE5pHxkwNZo",
        "outputId": "0940efe3-9848-43f9-e34c-8871713f9749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/mycar/models\n",
        "!cp /content/drive/My\\ Drive/myCar/base_linear.h5 ."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QtwcEli6yFrw"
      },
      "source": [
        "And untar it to the right place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urhFWBkUyGf0",
        "outputId": "7c0934d3-bc8c-41c1-eaaa-dd60fb4c574f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/mycar/data\n",
        "!tar -xzf {tub_name}.tar.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eyPsgV5KyFkg"
      },
      "source": [
        "To check whether data are available lets look at an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KsItvBTkzWcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "a6e8f6a7-99e7-4231-cd01-519cacdeedd1"
      },
      "source": [
        "from google.colab import files\n",
        "from IPython.display import Image\n",
        "import glob\n",
        "%cd /content/mycar/data/tubVaihingenIIICleaned200126/\n",
        "file = glob.glob(\"*.jpg\")\n",
        "Image(file[100])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar/data/tubVaihingenIIICleaned200126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ESiFEnkQ6WXp"
      },
      "source": [
        "## Transfer training of model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nRQ2eq6H84vl"
      },
      "source": [
        "Dont forget to set the variables in config.py  \n",
        "\n",
        "\n",
        "```\n",
        "FREEZE_LAYERS = True  \n",
        "`#default False will allow all layers to be modified by training\n",
        "\n",
        "NUM_LAST_LAYERS_TO_TRAIN = 7  \n",
        "`#when freezing layers, how many layers from the last should be allowed to train?\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0YHhDGJYvZ5u",
        "outputId": "dce25de1-0b7a-4bc2-8b83-89526c3b7f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/mycar/manage.py train  --type=linear --transfer=/content/mycar/models/base_linear.h5  --model=/content/mycar/models/mypilot.h5\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.1 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "loading personal config over-rides\n",
            "\n",
            "config loaded\n",
            "\"get_model_by_type\" model Type is: linear\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "training with model type <class 'donkeycar.parts.keras.KerasLinear'>\n",
            "loading weights from model /content/mycar/models/base_linear.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2020-03-01 20:15:10.883730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-01 20:15:10.947706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:10.948244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-01 20:15:10.959625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-01 20:15:11.211248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-01 20:15:11.355358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-01 20:15:11.375728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-01 20:15:11.655257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-01 20:15:11.674134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-01 20:15:12.199157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-01 20:15:12.199319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.200012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.200537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-01 20:15:12.201047: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-03-01 20:15:12.252078: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz\n",
            "2020-03-01 20:15:12.253836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6466fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-01 20:15:12.253872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-01 20:15:12.376300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.376808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6467180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-01 20:15:12.376842: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-03-01 20:15:12.378134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.378502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-01 20:15:12.378563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-01 20:15:12.378589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-01 20:15:12.378614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-01 20:15:12.378637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-01 20:15:12.378659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-01 20:15:12.378681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-01 20:15:12.378704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-01 20:15:12.378771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.379204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.379549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-01 20:15:12.384332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-01 20:15:12.385363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-01 20:15:12.385397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-01 20:15:12.385410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-01 20:15:12.386633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.387098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-01 20:15:12.387514: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-03-01 20:15:12.387563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_in (InputLayer)             [(None, 120, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d (Cropping2D)         (None, 120, 160, 3)  0           img_in[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 120, 160, 3)  12          cropping2d[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 58, 78, 24)   1824        batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 58, 78, 24)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 27, 37, 32)   19232       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 27, 37, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 12, 17, 64)   51264       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 12, 17, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 15, 64)   36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 10, 15, 64)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 13, 64)    36928       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 13, 64)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flattened (Flatten)             (None, 6656)         0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          665700      flattened[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 50)           5050        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 50)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs0 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs1 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 817,040\n",
            "Trainable params: 817,034\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "found 0 pickles writing json records and images in tub /content/mycar/data/tubVaihingenIIICleaned200126\n",
            "/content/mycar/data/tubVaihingenIIICleaned200126\n",
            "collating 14234 records ...\n",
            "train: 11387, val: 2847\n",
            "total records: 14234\n",
            "steps_per_epoch 177\n",
            "Epoch 1/100\n",
            "2020-03-01 20:15:22.207108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-01 20:15:23.704226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.3655 - n_outputs0_loss: 0.2319 - n_outputs1_loss: 0.1336Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 6s - loss: 0.6712 - n_outputs0_loss: 0.6156 - n_outputs1_loss: 0.0556\n",
            "Epoch 00001: val_loss improved from inf to 0.67117, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 20s 110ms/step - loss: 0.3644 - n_outputs0_loss: 0.2315 - n_outputs1_loss: 0.1329 - val_loss: 0.6712 - val_n_outputs0_loss: 0.6156 - val_n_outputs1_loss: 0.0556\n",
            "Epoch 2/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1945 - n_outputs0_loss: 0.1760 - n_outputs1_loss: 0.0186Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.6794 - n_outputs0_loss: 0.6145 - n_outputs1_loss: 0.0649\n",
            "Epoch 00002: val_loss did not improve from 0.67117\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.1942 - n_outputs0_loss: 0.1755 - n_outputs1_loss: 0.0187 - val_loss: 0.6821 - val_n_outputs0_loss: 0.6175 - val_n_outputs1_loss: 0.0646\n",
            "Epoch 3/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1753 - n_outputs0_loss: 0.1604 - n_outputs1_loss: 0.0149Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.6618 - n_outputs0_loss: 0.6397 - n_outputs1_loss: 0.0221\n",
            "Epoch 00003: val_loss improved from 0.67117 to 0.65910, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 41ms/step - loss: 0.1754 - n_outputs0_loss: 0.1603 - n_outputs1_loss: 0.0151 - val_loss: 0.6591 - val_n_outputs0_loss: 0.6367 - val_n_outputs1_loss: 0.0224\n",
            "Epoch 4/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1680 - n_outputs0_loss: 0.1541 - n_outputs1_loss: 0.0140Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.6526 - n_outputs0_loss: 0.6090 - n_outputs1_loss: 0.0437\n",
            "Epoch 00004: val_loss improved from 0.65910 to 0.65629, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 41ms/step - loss: 0.1682 - n_outputs0_loss: 0.1543 - n_outputs1_loss: 0.0139 - val_loss: 0.6563 - val_n_outputs0_loss: 0.6137 - val_n_outputs1_loss: 0.0426\n",
            "Epoch 5/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1555 - n_outputs0_loss: 0.1425 - n_outputs1_loss: 0.0131Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 1s - loss: 0.3074 - n_outputs0_loss: 0.2934 - n_outputs1_loss: 0.0140\n",
            "Epoch 00005: val_loss improved from 0.65629 to 0.30737, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 42ms/step - loss: 0.1554 - n_outputs0_loss: 0.1424 - n_outputs1_loss: 0.0130 - val_loss: 0.3074 - val_n_outputs0_loss: 0.2934 - val_n_outputs1_loss: 0.0140\n",
            "Epoch 6/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1444 - n_outputs0_loss: 0.1319 - n_outputs1_loss: 0.0125Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1706 - n_outputs0_loss: 0.1567 - n_outputs1_loss: 0.0139\n",
            "Epoch 00006: val_loss improved from 0.30737 to 0.16886, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 42ms/step - loss: 0.1445 - n_outputs0_loss: 0.1320 - n_outputs1_loss: 0.0124 - val_loss: 0.1689 - val_n_outputs0_loss: 0.1557 - val_n_outputs1_loss: 0.0132\n",
            "Epoch 7/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1409 - n_outputs0_loss: 0.1288 - n_outputs1_loss: 0.0121Epoch 1/100\n",
            " 43/177 [======>.......................] - ETA: 1s - loss: 0.1527 - n_outputs0_loss: 0.1426 - n_outputs1_loss: 0.0101\n",
            "Epoch 00007: val_loss improved from 0.16886 to 0.15216, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 42ms/step - loss: 0.1404 - n_outputs0_loss: 0.1283 - n_outputs1_loss: 0.0120 - val_loss: 0.1522 - val_n_outputs0_loss: 0.1422 - val_n_outputs1_loss: 0.0099\n",
            "Epoch 8/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1314 - n_outputs0_loss: 0.1197 - n_outputs1_loss: 0.0117Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1412 - n_outputs0_loss: 0.1300 - n_outputs1_loss: 0.0111\n",
            "Epoch 00008: val_loss improved from 0.15216 to 0.14233, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 41ms/step - loss: 0.1318 - n_outputs0_loss: 0.1202 - n_outputs1_loss: 0.0117 - val_loss: 0.1423 - val_n_outputs0_loss: 0.1312 - val_n_outputs1_loss: 0.0112\n",
            "Epoch 9/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1284 - n_outputs0_loss: 0.1176 - n_outputs1_loss: 0.0108Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1540 - n_outputs0_loss: 0.1463 - n_outputs1_loss: 0.0077\n",
            "Epoch 00009: val_loss did not improve from 0.14233\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.1285 - n_outputs0_loss: 0.1177 - n_outputs1_loss: 0.0108 - val_loss: 0.1513 - val_n_outputs0_loss: 0.1438 - val_n_outputs1_loss: 0.0076\n",
            "Epoch 10/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1196 - n_outputs0_loss: 0.1093 - n_outputs1_loss: 0.0103Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 1s - loss: 0.1441 - n_outputs0_loss: 0.1379 - n_outputs1_loss: 0.0062\n",
            "Epoch 00010: val_loss did not improve from 0.14233\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.1195 - n_outputs0_loss: 0.1092 - n_outputs1_loss: 0.0103 - val_loss: 0.1441 - val_n_outputs0_loss: 0.1379 - val_n_outputs1_loss: 0.0062\n",
            "Epoch 11/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1143 - n_outputs0_loss: 0.1052 - n_outputs1_loss: 0.0091Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 1s - loss: 0.1321 - n_outputs0_loss: 0.1267 - n_outputs1_loss: 0.0054\n",
            "Epoch 00011: val_loss improved from 0.14233 to 0.13208, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 41ms/step - loss: 0.1149 - n_outputs0_loss: 0.1057 - n_outputs1_loss: 0.0092 - val_loss: 0.1321 - val_n_outputs0_loss: 0.1267 - val_n_outputs1_loss: 0.0054\n",
            "Epoch 12/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1106 - n_outputs0_loss: 0.1008 - n_outputs1_loss: 0.0098Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1284 - n_outputs0_loss: 0.1249 - n_outputs1_loss: 0.0035\n",
            "Epoch 00012: val_loss improved from 0.13208 to 0.12771, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 42ms/step - loss: 0.1104 - n_outputs0_loss: 0.1006 - n_outputs1_loss: 0.0098 - val_loss: 0.1277 - val_n_outputs0_loss: 0.1243 - val_n_outputs1_loss: 0.0034\n",
            "Epoch 13/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1059 - n_outputs0_loss: 0.0968 - n_outputs1_loss: 0.0091Epoch 1/100\n",
            " 43/177 [======>.......................] - ETA: 1s - loss: 0.1298 - n_outputs0_loss: 0.1235 - n_outputs1_loss: 0.0063\n",
            "Epoch 00013: val_loss did not improve from 0.12771\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.1058 - n_outputs0_loss: 0.0968 - n_outputs1_loss: 0.0091 - val_loss: 0.1299 - val_n_outputs0_loss: 0.1237 - val_n_outputs1_loss: 0.0062\n",
            "Epoch 14/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.1016 - n_outputs0_loss: 0.0927 - n_outputs1_loss: 0.0089Epoch 1/100\n",
            " 43/177 [======>.......................] - ETA: 1s - loss: 0.1320 - n_outputs0_loss: 0.1264 - n_outputs1_loss: 0.0056\n",
            "Epoch 00014: val_loss did not improve from 0.12771\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.1016 - n_outputs0_loss: 0.0928 - n_outputs1_loss: 0.0088 - val_loss: 0.1333 - val_n_outputs0_loss: 0.1278 - val_n_outputs1_loss: 0.0055\n",
            "Epoch 15/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0953 - n_outputs0_loss: 0.0867 - n_outputs1_loss: 0.0086Epoch 1/100\n",
            " 43/177 [======>.......................] - ETA: 1s - loss: 0.1327 - n_outputs0_loss: 0.1282 - n_outputs1_loss: 0.0045\n",
            "Epoch 00015: val_loss did not improve from 0.12771\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0952 - n_outputs0_loss: 0.0867 - n_outputs1_loss: 0.0086 - val_loss: 0.1324 - val_n_outputs0_loss: 0.1280 - val_n_outputs1_loss: 0.0045\n",
            "Epoch 16/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0932 - n_outputs0_loss: 0.0850 - n_outputs1_loss: 0.0082Epoch 1/100\n",
            " 43/177 [======>.......................] - ETA: 1s - loss: 0.1232 - n_outputs0_loss: 0.1163 - n_outputs1_loss: 0.0068\n",
            "Epoch 00016: val_loss improved from 0.12771 to 0.12196, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 42ms/step - loss: 0.0933 - n_outputs0_loss: 0.0851 - n_outputs1_loss: 0.0082 - val_loss: 0.1220 - val_n_outputs0_loss: 0.1152 - val_n_outputs1_loss: 0.0068\n",
            "Epoch 17/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0903 - n_outputs0_loss: 0.0825 - n_outputs1_loss: 0.0078Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 1s - loss: 0.1336 - n_outputs0_loss: 0.1273 - n_outputs1_loss: 0.0063\n",
            "Epoch 00017: val_loss did not improve from 0.12196\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0904 - n_outputs0_loss: 0.0826 - n_outputs1_loss: 0.0078 - val_loss: 0.1336 - val_n_outputs0_loss: 0.1273 - val_n_outputs1_loss: 0.0063\n",
            "Epoch 18/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0875 - n_outputs0_loss: 0.0799 - n_outputs1_loss: 0.0076Epoch 1/100\n",
            " 43/177 [======>.......................] - ETA: 1s - loss: 0.1270 - n_outputs0_loss: 0.1214 - n_outputs1_loss: 0.0056\n",
            "Epoch 00018: val_loss did not improve from 0.12196\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0877 - n_outputs0_loss: 0.0801 - n_outputs1_loss: 0.0075 - val_loss: 0.1264 - val_n_outputs0_loss: 0.1209 - val_n_outputs1_loss: 0.0055\n",
            "Epoch 19/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0853 - n_outputs0_loss: 0.0777 - n_outputs1_loss: 0.0076Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1246 - n_outputs0_loss: 0.1173 - n_outputs1_loss: 0.0073\n",
            "Epoch 00019: val_loss did not improve from 0.12196\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0852 - n_outputs0_loss: 0.0777 - n_outputs1_loss: 0.0075 - val_loss: 0.1235 - val_n_outputs0_loss: 0.1157 - val_n_outputs1_loss: 0.0078\n",
            "Epoch 20/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0833 - n_outputs0_loss: 0.0759 - n_outputs1_loss: 0.0074Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 1s - loss: 0.1280 - n_outputs0_loss: 0.1212 - n_outputs1_loss: 0.0068\n",
            "Epoch 00020: val_loss did not improve from 0.12196\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0831 - n_outputs0_loss: 0.0757 - n_outputs1_loss: 0.0074 - val_loss: 0.1280 - val_n_outputs0_loss: 0.1212 - val_n_outputs1_loss: 0.0068\n",
            "Epoch 21/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0799 - n_outputs0_loss: 0.0728 - n_outputs1_loss: 0.0072Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 1s - loss: 0.1210 - n_outputs0_loss: 0.1159 - n_outputs1_loss: 0.0051\n",
            "Epoch 00021: val_loss improved from 0.12196 to 0.12104, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 41ms/step - loss: 0.0800 - n_outputs0_loss: 0.0728 - n_outputs1_loss: 0.0071 - val_loss: 0.1210 - val_n_outputs0_loss: 0.1159 - val_n_outputs1_loss: 0.0051\n",
            "Epoch 22/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0781 - n_outputs0_loss: 0.0712 - n_outputs1_loss: 0.0069Epoch 1/100\n",
            " 42/177 [======>.......................] - ETA: 1s - loss: 0.1234 - n_outputs0_loss: 0.1171 - n_outputs1_loss: 0.0062\n",
            "Epoch 00022: val_loss did not improve from 0.12104\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0784 - n_outputs0_loss: 0.0716 - n_outputs1_loss: 0.0069 - val_loss: 0.1247 - val_n_outputs0_loss: 0.1187 - val_n_outputs1_loss: 0.0060\n",
            "Epoch 23/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0753 - n_outputs0_loss: 0.0683 - n_outputs1_loss: 0.0070Epoch 1/100\n",
            " 40/177 [=====>........................] - ETA: 1s - loss: 0.1234 - n_outputs0_loss: 0.1173 - n_outputs1_loss: 0.0062\n",
            "Epoch 00023: val_loss did not improve from 0.12104\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0755 - n_outputs0_loss: 0.0686 - n_outputs1_loss: 0.0069 - val_loss: 0.1263 - val_n_outputs0_loss: 0.1206 - val_n_outputs1_loss: 0.0057\n",
            "Epoch 24/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0745 - n_outputs0_loss: 0.0680 - n_outputs1_loss: 0.0065Epoch 1/100\n",
            " 43/177 [======>.......................] - ETA: 1s - loss: 0.1170 - n_outputs0_loss: 0.1110 - n_outputs1_loss: 0.0060\n",
            "Epoch 00024: val_loss improved from 0.12104 to 0.11585, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 7s 42ms/step - loss: 0.0746 - n_outputs0_loss: 0.0680 - n_outputs1_loss: 0.0065 - val_loss: 0.1159 - val_n_outputs0_loss: 0.1100 - val_n_outputs1_loss: 0.0059\n",
            "Epoch 25/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0713 - n_outputs0_loss: 0.0647 - n_outputs1_loss: 0.0066Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1176 - n_outputs0_loss: 0.1096 - n_outputs1_loss: 0.0080\n",
            "Epoch 00025: val_loss did not improve from 0.11585\n",
            "177/177 [==============================] - 7s 41ms/step - loss: 0.0714 - n_outputs0_loss: 0.0649 - n_outputs1_loss: 0.0066 - val_loss: 0.1177 - val_n_outputs0_loss: 0.1100 - val_n_outputs1_loss: 0.0078\n",
            "Epoch 26/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0685 - n_outputs0_loss: 0.0624 - n_outputs1_loss: 0.0061Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1245 - n_outputs0_loss: 0.1176 - n_outputs1_loss: 0.0069\n",
            "Epoch 00026: val_loss did not improve from 0.11585\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0683 - n_outputs0_loss: 0.0622 - n_outputs1_loss: 0.0062 - val_loss: 0.1233 - val_n_outputs0_loss: 0.1159 - val_n_outputs1_loss: 0.0074\n",
            "Epoch 27/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0681 - n_outputs0_loss: 0.0619 - n_outputs1_loss: 0.0062Epoch 1/100\n",
            " 42/177 [======>.......................] - ETA: 1s - loss: 0.1254 - n_outputs0_loss: 0.1200 - n_outputs1_loss: 0.0054\n",
            "Epoch 00027: val_loss did not improve from 0.11585\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0680 - n_outputs0_loss: 0.0618 - n_outputs1_loss: 0.0062 - val_loss: 0.1232 - val_n_outputs0_loss: 0.1178 - val_n_outputs1_loss: 0.0054\n",
            "Epoch 28/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0651 - n_outputs0_loss: 0.0592 - n_outputs1_loss: 0.0059Epoch 1/100\n",
            " 41/177 [=====>........................] - ETA: 1s - loss: 0.1195 - n_outputs0_loss: 0.1108 - n_outputs1_loss: 0.0087\n",
            "Epoch 00028: val_loss did not improve from 0.11585\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0651 - n_outputs0_loss: 0.0592 - n_outputs1_loss: 0.0059 - val_loss: 0.1193 - val_n_outputs0_loss: 0.1111 - val_n_outputs1_loss: 0.0082\n",
            "Epoch 29/100\n",
            "175/177 [============================>.] - ETA: 0s - loss: 0.0630 - n_outputs0_loss: 0.0571 - n_outputs1_loss: 0.0060Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 1s - loss: 0.1170 - n_outputs0_loss: 0.1091 - n_outputs1_loss: 0.0079\n",
            "Epoch 00029: val_loss did not improve from 0.11585\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 0.0631 - n_outputs0_loss: 0.0572 - n_outputs1_loss: 0.0059 - val_loss: 0.1170 - val_n_outputs0_loss: 0.1091 - val_n_outputs1_loss: 0.0079\n",
            "Epoch 00029: early stopping\n",
            "Training completed in 0:03:42.\n",
            "\n",
            "\n",
            "----------- Best Eval Loss :0.115850 ---------\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T3Ya8qEUAfOv"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "edH3xO_AVWXu",
        "outputId": "0204ce51-3cf4-4acb-b5f0-32a095feacfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/mycar/manage.py train --type rnn --model /content/mycar/models/mypilot.h5 --aug"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.1 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "loading personal config over-rides\n",
            "\n",
            "config loaded\n",
            "sequence of images training\n",
            "\"get_model_by_type\" model Type is: rnn\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Tub: /content/mycar/data/tubVaihingenIIICleaned200126 has 14234 records\n",
            "collating records\n",
            "collating sequences\n",
            "collated 14169 sequences of length 6\n",
            "train: 11336, validation: 2833\n",
            "steps_per_epoch 177\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2020-03-02 10:54:21.132316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-02 10:54:21.184607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:21.185259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-02 10:54:21.198151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-02 10:54:21.423175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-02 10:54:21.552103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-02 10:54:21.571738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-02 10:54:21.843144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-02 10:54:21.860870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-02 10:54:22.395873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-02 10:54:22.396042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.396926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.397639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-02 10:54:22.399069: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-03-02 10:54:22.437048: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz\n",
            "2020-03-02 10:54:22.437494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18fcf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-02 10:54:22.437537: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-02 10:54:22.612526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.613280: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18fdb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-02 10:54:22.613666: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-03-02 10:54:22.614994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.615659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-02 10:54:22.615753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-02 10:54:22.616801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-02 10:54:22.616847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-02 10:54:22.616877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-02 10:54:22.616901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-02 10:54:22.616923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-02 10:54:22.616946: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-02 10:54:22.617032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.617782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.618298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-02 10:54:22.621633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-02 10:54:22.623067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-02 10:54:22.623106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-02 10:54:22.623177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-02 10:54:22.624514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.625218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-02 10:54:22.625802: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-03-02 10:54:22.625854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "2020-03-02 10:54:30.771371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-02 10:54:32.314857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.3324Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 27s - loss: 0.3010\n",
            "Epoch 00001: val_loss improved from inf to 0.30102, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 80s 454ms/step - loss: 0.3318 - val_loss: 0.3010\n",
            "Epoch 2/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.3057Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 20s - loss: 0.3038\n",
            "Epoch 00002: val_loss did not improve from 0.30102\n",
            "177/177 [==============================] - 43s 242ms/step - loss: 0.3062 - val_loss: 0.3038\n",
            "Epoch 3/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.3042Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 15s - loss: 0.2919\n",
            "Epoch 00003: val_loss improved from 0.30102 to 0.29193, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 41s 233ms/step - loss: 0.3040 - val_loss: 0.2919\n",
            "Epoch 4/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.2140Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.1228\n",
            "Epoch 00004: val_loss improved from 0.29193 to 0.12281, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 238ms/step - loss: 0.2135 - val_loss: 0.1228\n",
            "Epoch 5/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.1206Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0975\n",
            "Epoch 00005: val_loss improved from 0.12281 to 0.09747, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 237ms/step - loss: 0.1206 - val_loss: 0.0975\n",
            "Epoch 6/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.1046Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 18s - loss: 0.0939\n",
            "Epoch 00006: val_loss improved from 0.09747 to 0.09393, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 239ms/step - loss: 0.1046 - val_loss: 0.0939\n",
            "Epoch 7/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0984Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 15s - loss: 0.0828\n",
            "Epoch 00007: val_loss improved from 0.09393 to 0.08277, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0984 - val_loss: 0.0828\n",
            "Epoch 8/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0921Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0827\n",
            "Epoch 00008: val_loss improved from 0.08277 to 0.08269, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0921 - val_loss: 0.0827\n",
            "Epoch 9/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0882Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0765\n",
            "Epoch 00009: val_loss improved from 0.08269 to 0.07652, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 239ms/step - loss: 0.0881 - val_loss: 0.0765\n",
            "Epoch 10/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0841Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0796\n",
            "Epoch 00010: val_loss did not improve from 0.07652\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0842 - val_loss: 0.0796\n",
            "Epoch 11/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0806Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0780\n",
            "Epoch 00011: val_loss did not improve from 0.07652\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0807 - val_loss: 0.0780\n",
            "Epoch 12/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0767Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0689\n",
            "Epoch 00012: val_loss improved from 0.07652 to 0.06885, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 239ms/step - loss: 0.0766 - val_loss: 0.0689\n",
            "Epoch 13/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0743Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0671\n",
            "Epoch 00013: val_loss improved from 0.06885 to 0.06709, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 238ms/step - loss: 0.0743 - val_loss: 0.0671\n",
            "Epoch 14/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0720Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 15s - loss: 0.0648\n",
            "Epoch 00014: val_loss improved from 0.06709 to 0.06479, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0719 - val_loss: 0.0648\n",
            "Epoch 15/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0705Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0607\n",
            "Epoch 00015: val_loss improved from 0.06479 to 0.06068, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0705 - val_loss: 0.0607\n",
            "Epoch 16/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0669Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 15s - loss: 0.0621\n",
            "Epoch 00016: val_loss did not improve from 0.06068\n",
            "177/177 [==============================] - 41s 232ms/step - loss: 0.0670 - val_loss: 0.0621\n",
            "Epoch 17/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0650Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0604\n",
            "Epoch 00017: val_loss improved from 0.06068 to 0.06036, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0650 - val_loss: 0.0604\n",
            "Epoch 18/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0636Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0613\n",
            "Epoch 00018: val_loss did not improve from 0.06036\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0636 - val_loss: 0.0613\n",
            "Epoch 19/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0605Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0585\n",
            "Epoch 00019: val_loss improved from 0.06036 to 0.05849, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0606 - val_loss: 0.0585\n",
            "Epoch 20/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0586Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0557\n",
            "Epoch 00020: val_loss improved from 0.05849 to 0.05567, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 238ms/step - loss: 0.0587 - val_loss: 0.0557\n",
            "Epoch 21/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0573Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 18s - loss: 0.0520\n",
            "Epoch 00021: val_loss improved from 0.05567 to 0.05205, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 239ms/step - loss: 0.0575 - val_loss: 0.0520\n",
            "Epoch 22/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0547Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0518\n",
            "Epoch 00022: val_loss improved from 0.05205 to 0.05184, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 237ms/step - loss: 0.0547 - val_loss: 0.0518\n",
            "Epoch 23/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0554Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0508\n",
            "Epoch 00023: val_loss improved from 0.05184 to 0.05078, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0553 - val_loss: 0.0508\n",
            "Epoch 24/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0520Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0550\n",
            "Epoch 00024: val_loss did not improve from 0.05078\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0522 - val_loss: 0.0550\n",
            "Epoch 25/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0513Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0483\n",
            "Epoch 00025: val_loss improved from 0.05078 to 0.04827, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0514 - val_loss: 0.0483\n",
            "Epoch 26/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0499Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0502\n",
            "Epoch 00026: val_loss did not improve from 0.04827\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0497 - val_loss: 0.0502\n",
            "Epoch 27/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0506Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0449\n",
            "Epoch 00027: val_loss improved from 0.04827 to 0.04485, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0506 - val_loss: 0.0449\n",
            "Epoch 28/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0477Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0491\n",
            "Epoch 00028: val_loss did not improve from 0.04485\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0476 - val_loss: 0.0491\n",
            "Epoch 29/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0470Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0508\n",
            "Epoch 00029: val_loss did not improve from 0.04485\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0471 - val_loss: 0.0508\n",
            "Epoch 30/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0449Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0444\n",
            "Epoch 00030: val_loss improved from 0.04485 to 0.04441, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 238ms/step - loss: 0.0448 - val_loss: 0.0444\n",
            "Epoch 31/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0433Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0420\n",
            "Epoch 00031: val_loss improved from 0.04441 to 0.04200, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 237ms/step - loss: 0.0433 - val_loss: 0.0420\n",
            "Epoch 32/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0439Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0436\n",
            "Epoch 00032: val_loss did not improve from 0.04200\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0438 - val_loss: 0.0436\n",
            "Epoch 33/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0429Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0443\n",
            "Epoch 00033: val_loss did not improve from 0.04200\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0430 - val_loss: 0.0443\n",
            "Epoch 34/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0409Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0427\n",
            "Epoch 00034: val_loss did not improve from 0.04200\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0410 - val_loss: 0.0427\n",
            "Epoch 35/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0419Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0433\n",
            "Epoch 00035: val_loss did not improve from 0.04200\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0418 - val_loss: 0.0433\n",
            "Epoch 36/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0410Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0394\n",
            "Epoch 00036: val_loss improved from 0.04200 to 0.03945, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0409 - val_loss: 0.0394\n",
            "Epoch 37/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0404Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0410\n",
            "Epoch 00037: val_loss did not improve from 0.03945\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0402 - val_loss: 0.0410\n",
            "Epoch 38/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0401Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0385\n",
            "Epoch 00038: val_loss improved from 0.03945 to 0.03854, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0400 - val_loss: 0.0385\n",
            "Epoch 39/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0379Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0397\n",
            "Epoch 00039: val_loss did not improve from 0.03854\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0381 - val_loss: 0.0397\n",
            "Epoch 40/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0371Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0423\n",
            "Epoch 00040: val_loss did not improve from 0.03854\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0372 - val_loss: 0.0423\n",
            "Epoch 41/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0369Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0421\n",
            "Epoch 00041: val_loss did not improve from 0.03854\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0370 - val_loss: 0.0421\n",
            "Epoch 42/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0358Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0373\n",
            "Epoch 00042: val_loss improved from 0.03854 to 0.03727, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0358 - val_loss: 0.0373\n",
            "Epoch 43/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0366Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0380\n",
            "Epoch 00043: val_loss did not improve from 0.03727\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0366 - val_loss: 0.0380\n",
            "Epoch 44/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0355Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0401\n",
            "Epoch 00044: val_loss did not improve from 0.03727\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0355 - val_loss: 0.0401\n",
            "Epoch 45/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0352Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0368\n",
            "Epoch 00045: val_loss improved from 0.03727 to 0.03677, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 238ms/step - loss: 0.0352 - val_loss: 0.0368\n",
            "Epoch 46/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0355Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0365\n",
            "Epoch 00046: val_loss improved from 0.03677 to 0.03652, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0356 - val_loss: 0.0365\n",
            "Epoch 47/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0346Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 17s - loss: 0.0405\n",
            "Epoch 00047: val_loss did not improve from 0.03652\n",
            "177/177 [==============================] - 42s 236ms/step - loss: 0.0346 - val_loss: 0.0405\n",
            "Epoch 48/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0343Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0352\n",
            "Epoch 00048: val_loss improved from 0.03652 to 0.03524, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 237ms/step - loss: 0.0343 - val_loss: 0.0352\n",
            "Epoch 49/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0328Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 18s - loss: 0.0353\n",
            "Epoch 00049: val_loss did not improve from 0.03524\n",
            "177/177 [==============================] - 42s 238ms/step - loss: 0.0329 - val_loss: 0.0353\n",
            "Epoch 50/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0332Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 15s - loss: 0.0392\n",
            "Epoch 00050: val_loss did not improve from 0.03524\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0331 - val_loss: 0.0392\n",
            "Epoch 51/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0322Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 15s - loss: 0.0351\n",
            "Epoch 00051: val_loss improved from 0.03524 to 0.03511, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 41s 233ms/step - loss: 0.0322 - val_loss: 0.0351\n",
            "Epoch 52/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0311Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0355\n",
            "Epoch 00052: val_loss did not improve from 0.03511\n",
            "177/177 [==============================] - 41s 233ms/step - loss: 0.0311 - val_loss: 0.0355\n",
            "Epoch 53/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0316Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0334\n",
            "Epoch 00053: val_loss improved from 0.03511 to 0.03341, saving model to /content/mycar/models/mypilot.h5\n",
            "177/177 [==============================] - 42s 234ms/step - loss: 0.0317 - val_loss: 0.0334\n",
            "Epoch 54/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0313Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0343\n",
            "Epoch 00054: val_loss did not improve from 0.03341\n",
            "177/177 [==============================] - 41s 233ms/step - loss: 0.0313 - val_loss: 0.0343\n",
            "Epoch 55/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0313Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0354\n",
            "Epoch 00055: val_loss did not improve from 0.03341\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0314 - val_loss: 0.0354\n",
            "Epoch 56/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0303Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0353\n",
            "Epoch 00056: val_loss did not improve from 0.03341\n",
            "177/177 [==============================] - 42s 235ms/step - loss: 0.0304 - val_loss: 0.0353\n",
            "Epoch 57/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0312Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0344\n",
            "Epoch 00057: val_loss did not improve from 0.03341\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0312 - val_loss: 0.0344\n",
            "Epoch 58/100\n",
            "176/177 [============================>.] - ETA: 0s - loss: 0.0316Epoch 1/100\n",
            " 44/177 [======>.......................] - ETA: 16s - loss: 0.0341\n",
            "Epoch 00058: val_loss did not improve from 0.03341\n",
            "177/177 [==============================] - 41s 234ms/step - loss: 0.0316 - val_loss: 0.0341\n",
            "Epoch 00058: early stopping\n",
            "Training completed in 0:40:58.\n",
            "\n",
            "\n",
            "----------- Best Eval Loss :0.033409 ---------\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rXzn1noJz5MQ"
      },
      "source": [
        "Check if the model is generated\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AixQrFy_z3vv",
        "outputId": "100bef5e-ed30-4016-b416-f8f9812bd73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "%cd /content/mycar/models\n",
        "file = glob.glob(\"*.png\")\n",
        "Image(file[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar/models\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMBIAhRBCCCECzP8HHkZbxJ5jgqoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6BEOJYH601O0"
      },
      "source": [
        "## Copy the trained model back to Donkey Car (Pi)\n",
        "\n",
        "Once the training is complete on Colab, download\n",
        "\n",
        "\n",
        "*   mypilot.h5 file from /content/mycar/models/ \n",
        "*   myconfig.py file from /content/mycar/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YtvyJpOdocjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbee12cf-d405-4878-8e15-feec1e3b2e30"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./mypilot.h5')\n",
        "\n",
        "%cd /content/mycar\n",
        "\n",
        "files.download('myconfig.py')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i7AIY6yBOCM-"
      },
      "source": [
        "Alternatively, you can copy the model back to Google Drive too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Dim4fCpOBo9",
        "colab": {}
      },
      "source": [
        "!cp /content/mycar/models/mypilot.h5 /content/drive/My\\ Drive/myCar/mypilot.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GpkOVzh86omO"
      },
      "source": [
        "### Copy the file from your PC or Mac to the Raspberry Pi using Filezilla or scp command.\n",
        "\n",
        "```\n",
        "sftp pi@raspberry.local\n",
        "cd mycar/models\n",
        "put mypilot.h5\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hfERkGy821Xy"
      },
      "source": [
        "## Start Autopilot on Pi\n",
        "\n",
        "\n",
        "```bash\n",
        "cd ~/mycar\n",
        "python manage.py drive --model models/mypilot.h5 --js\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X93SodzAv9hV"
      },
      "source": [
        "## Bonus - Salient Object Visualization\n",
        "> Note: It seems like the salient mode doesn't work for RNN networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4AZvWSeiyqto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "9ef17996-a87d-477c-e5dd-bb47368ebacb"
      },
      "source": [
        "# !pip install git+https://github.com/autorope/keras-vis.git\n",
        "!pip uninstall keras-vis\n",
        "!pip install git+https://github.com/sctse999/keras-vis\n",
        "  \n",
        "  "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling keras-vis-0.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/*\n",
            "    /usr/local/lib/python3.6/dist-packages/keras_vis-0.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/vis/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/autogen.py\n",
            "    /usr/local/lib/python3.6/dist-packages/docs/structure.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled keras-vis-0.4.1\n",
            "Collecting git+https://github.com/sctse999/keras-vis\n",
            "  Cloning https://github.com/sctse999/keras-vis to /tmp/pip-req-build-fppmjn_o\n",
            "  Running command git clone -q https://github.com/sctse999/keras-vis /tmp/pip-req-build-fppmjn_o\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (0.16.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (3.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (2.8.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (2.4)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (6.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (2.6.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->keras-vis==0.5.0) (4.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->keras-vis==0.5.0) (45.1.0)\n",
            "Building wheels for collected packages: keras-vis\n",
            "  Building wheel for keras-vis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vis: filename=keras_vis-0.5.0-py2.py3-none-any.whl size=38989 sha256=3425b80d2a4c02e113e49cc0eac6273520739475597a75c838d65a26dba7950b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ih_t8yg/wheels/29/87/8e/abd2257f08391eabe7552711aecf08cbb50f79877210b21be0\n",
            "Successfully built keras-vis\n",
            "Installing collected packages: keras-vis\n",
            "Successfully installed keras-vis-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKI37gVrv9Q8",
        "colab": {}
      },
      "source": [
        "%cd /content/mycar\n",
        "!donkey makemovie --tub data/{tub_name} --model models/mypilot.h5 --type linear --salient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7Rh-PlQFCkR",
        "colab_type": "text"
      },
      "source": [
        "Download the movie to local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IcUrgOq_pePV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b5a868ff-f35f-4a08-ecdf-40fc79114e82"
      },
      "source": [
        "\n",
        "%cd /content/mycar\n",
        "!ls -ahl\n",
        "files.download('tub_movie.mp4')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar\n",
            "total 89M\n",
            "drwxr-xr-x 6 root root 4.0K Mar  2 11:48 .\n",
            "drwxr-xr-x 1 root root 4.0K Mar  2 10:52 ..\n",
            "-rw-r--r-- 1 root root  13K Mar  2 10:51 config.py\n",
            "drwxr-xr-x 3 root root 4.0K Mar  2 10:52 data\n",
            "drwxr-xr-x 2 root root 4.0K Mar  2 10:51 logs\n",
            "-rw-r--r-- 1 root root  23K Mar  2 10:51 manage.py\n",
            "drwxr-xr-x 2 root root 4.0K Mar  2 11:35 models\n",
            "-rw-r--r-- 1 root root  14K Mar  2 10:52 myconfig.py\n",
            "-rw-r--r-- 1 root root 1.8M Mar  2 11:46 mypilot.h5\n",
            "drwxr-xr-x 2 root root 4.0K Mar  2 10:54 __pycache__\n",
            "-rw-r--r-- 1 root root  39K Mar  2 10:51 train.py\n",
            "-rw-r--r-- 1 root root  39M Mar  2 11:50 tub_movie.mp4\n",
            "-rw------- 1 root root  49M Mar  2 11:46 tubVaihingenIIICleaned200126.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9naBRC-GZ82",
        "colab_type": "text"
      },
      "source": [
        "Or download the file to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwXuQ7vhGh6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/mycar/tub_movie.mp4 /content/drive/My\\ Drive/myCar/tub_movie.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}